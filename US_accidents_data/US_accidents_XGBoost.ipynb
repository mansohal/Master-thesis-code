{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Severity                                        Description  \\\n",
      "0         3  Right lane blocked due to accident on I-70 Eas...   \n",
      "1         2  Accident on Brice Rd at Tussing Rd. Expect del...   \n",
      "2         2  Accident on OH-32 State Route 32 Westbound at ...   \n",
      "3         3  Accident on I-75 Southbound at Exits 52 52B US...   \n",
      "4         2  Accident on McEwen Rd at OH-725 Miamisburg Cen...   \n",
      "\n",
      "                      Street          City State Country  Temperature(F)  \\\n",
      "0                     I-70 E        Dayton    OH      US            36.9   \n",
      "1                   Brice Rd  Reynoldsburg    OH      US            37.9   \n",
      "2             State Route 32  Williamsburg    OH      US            36.0   \n",
      "3                     I-75 S        Dayton    OH      US            35.1   \n",
      "4  Miamisburg Centerville Rd        Dayton    OH      US            36.0   \n",
      "\n",
      "   Wind_Chill(F)  Humidity(%)  Pressure(in)  Visibility(mi) Wind_Direction  \\\n",
      "0            NaN         91.0         29.68            10.0           Calm   \n",
      "1            NaN        100.0         29.65            10.0           Calm   \n",
      "2           33.3        100.0         29.67            10.0             SW   \n",
      "3           31.0         96.0         29.64             9.0             SW   \n",
      "4           33.3         89.0         29.65             6.0             SW   \n",
      "\n",
      "   Wind_Speed(mph) Weather_Condition  \n",
      "0              NaN        Light Rain  \n",
      "1              NaN        Light Rain  \n",
      "2              3.5          Overcast  \n",
      "3              4.6     Mostly Cloudy  \n",
      "4              3.5     Mostly Cloudy  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset with only the necessary columns\n",
    "selected_columns = ['Severity', 'Description', 'Street', 'City', 'State', \n",
    "                    'Country', 'Temperature(F)', 'Wind_Chill(F)', 'Humidity(%)',\n",
    "                    'Pressure(in)', 'Visibility(mi)', 'Wind_Direction', \n",
    "                    'Wind_Speed(mph)', 'Weather_Condition']\n",
    "\n",
    "df = pd.read_csv('E:/Master_thesis_REV/Datasets/Dataset_US_accidents/archive/US_Accidents_March23.csv', usecols=selected_columns, encoding='utf-8')\n",
    "\n",
    "# Display the first few rows to check the data\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Severity  Description   Street     City   State  Country  Temperature(F)  \\\n",
      "2         2          1.0    252.0   3010.0  118115  7728394            36.0   \n",
      "3         3          5.0  27546.0  24572.0  118115  7728394            35.1   \n",
      "4         2          2.0    729.0  24572.0  118115  7728394            36.0   \n",
      "5         3          1.0    104.0   1073.0  118115  7728394            37.9   \n",
      "6         2          1.0     26.0  24572.0  118115  7728394            34.0   \n",
      "\n",
      "   Wind_Chill(F)  Humidity(%)  Pressure(in)  Visibility(mi)  Wind_Direction  \\\n",
      "2           33.3        100.0         29.67            10.0        364470.0   \n",
      "3           31.0         96.0         29.64             9.0        364470.0   \n",
      "4           33.3         89.0         29.65             6.0        364470.0   \n",
      "5           35.5         97.0         29.63             7.0        384840.0   \n",
      "6           31.0        100.0         29.66             7.0        353806.0   \n",
      "\n",
      "   Wind_Speed(mph)  Weather_Condition  \n",
      "2              3.5           382866.0  \n",
      "3              4.6          1016195.0  \n",
      "4              3.5          1016195.0  \n",
      "5              3.5           352957.0  \n",
      "6              3.5           382866.0  \n"
     ]
    }
   ],
   "source": [
    "# Handle missing values - example with 'Wind_Speed(mph)'\n",
    "df['Wind_Speed(mph)'].fillna(df['Wind_Speed(mph)'].mean(), inplace=True)\n",
    "\n",
    "# Frequency encoding for categorical columns\n",
    "categorical_columns = ['Description', 'Street', 'City', 'State', 'Country', 'Weather_Condition', 'Wind_Direction']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    freq = df[col].value_counts()\n",
    "    df[col] = df[col].map(freq)\n",
    "\n",
    "# Drop any remaining rows with missing values if necessary\n",
    "df = df.dropna()\n",
    "\n",
    "# Display the first few rows after preprocessing\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (5676313, 13), y shape: (5676313,)\n"
     ]
    }
   ],
   "source": [
    "# Define features (X) and target (y)\n",
    "X = df.drop(columns=['Severity'])\n",
    "y = df['Severity']\n",
    "\n",
    "# Display the shapes of X and y to confirm\n",
    "print(f'X shape: {X.shape}, y shape: {y.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to sample data\n",
    "def sample_data(X, y, sample_size):\n",
    "    if isinstance(sample_size, float):\n",
    "        if 0 < sample_size < 1.0:\n",
    "            return train_test_split(X, y, test_size=0.2, train_size=sample_size, random_state=42)\n",
    "        elif sample_size == 1.0:\n",
    "            return train_test_split(X, y, test_size=0.001, random_state=42)\n",
    "        else:\n",
    "            raise ValueError(\"sample_size as float must be in the range (0.0, 1.0) or equal to 1.0.\")\n",
    "    elif isinstance(sample_size, int):\n",
    "        if sample_size > len(X):\n",
    "            raise ValueError(f\"sample_size {sample_size} exceeds the number of available samples {len(X)}.\")\n",
    "        sampled_X = X.sample(n=sample_size, random_state=42)\n",
    "        sampled_y = y.loc[sampled_X.index]\n",
    "        return train_test_split(sampled_X, sampled_y, test_size=0.2, random_state=42)\n",
    "    else:\n",
    "        raise ValueError(\"sample_size must be a float or an integer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "import numpy as np\n",
    "import time\n",
    "import psutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate and return metrics\n",
    "def calculate_metrics(X_train, X_test, y_train, y_test):\n",
    "    model = xgb.XGBRegressor(random_state=42)\n",
    "\n",
    "    # Define hyperparameters for RandomizedSearchCV\n",
    "    param_distributions = {\n",
    "        'n_estimators': [50, 100],  # Reduced number of trees\n",
    "        'max_depth': [2, 4, 6, 8, 10],  # Shallower trees for faster training\n",
    "        'learning_rate': [0.05, 0.1],  # Slightly higher learning rate for quicker convergence\n",
    "        'subsample': [0.8, 1.0],  # Fixed subsample ratio for speed\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],  # Fixed column sample ratio\n",
    "        'gamma': [0, 0.1],  # Reduced regularization to speed up training\n",
    "        'min_child_weight': [1, 3]  # Balanced min_child_weight for regularization\n",
    "    }\n",
    "\n",
    "    random_search = RandomizedSearchCV(model, param_distributions, n_iter=20, cv=3, scoring='neg_mean_squared_error', random_state=42, n_jobs=-1, verbose=2)\n",
    "\n",
    "    start_time = time.time()\n",
    "    start_cpu = psutil.cpu_percent(interval=None)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    end_cpu = psutil.cpu_percent(interval=None)\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calculate time and CPU usage\n",
    "    execution_time = end_time - start_time\n",
    "    avg_cpu_usage = (start_cpu + end_cpu) / 2\n",
    "\n",
    "    y_pred = random_search.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    # Calculate the range of the target variable\n",
    "    target_range = y_train.max() - y_train.min()\n",
    "\n",
    "    # Calculate normalized RMSE (nRMSE)\n",
    "    nrmse = rmse / target_range\n",
    "    \n",
    "    memory_usage_MB = X_train.memory_usage(deep=True).sum() / (1024 ** 2)\n",
    "    normalized_time = execution_time / memory_usage_MB\n",
    "    \n",
    "    return {\n",
    "        'RMSE': rmse,\n",
    "        'MAPE': mape,\n",
    "        'R2': r2,\n",
    "        'MSE': mse,\n",
    "        'nRMSE': nrmse,  # Normalized RMSE\n",
    "        'Execution Time (Raw)': execution_time,  # Raw execution time\n",
    "        'Normalized Time (s/MB)': normalized_time,  # Normalized execution time\n",
    "        'Average CPU Usage': avg_cpu_usage\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Metrics for sample size 1.0:\n",
      "RMSE: 0.40647984879606164\n",
      "MAPE: 0.10300810677874607\n",
      "R2: 0.22285483205085077\n",
      "MSE: 0.1652258674772691\n",
      "nRMSE: 0.13549328293202054\n",
      "Execution Time (Raw): 722.9404819011688\n",
      "Normalized Time (s/MB): 1.1935831088403739\n",
      "Average CPU Usage: 47.099999999999994\n",
      "Sample Size: 1.0\n",
      "--------------------------------------------------\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Metrics for sample size 0.5:\n",
      "RMSE: 0.4053879813870316\n",
      "MAPE: 0.10061538489967169\n",
      "R2: 0.21124466498771444\n",
      "MSE: 0.16433941545305228\n",
      "nRMSE: 0.13512932712901052\n",
      "Execution Time (Raw): 320.74198174476624\n",
      "Normalized Time (s/MB): 1.0580384142593693\n",
      "Average CPU Usage: 52.4\n",
      "Sample Size: 0.5\n",
      "--------------------------------------------------\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Metrics for sample size 0.25:\n",
      "RMSE: 0.40657563944092123\n",
      "MAPE: 0.10086485119510333\n",
      "R2: 0.20661628974747348\n",
      "MSE: 0.165303750586794\n",
      "nRMSE: 0.13552521314697374\n",
      "Execution Time (Raw): 144.04794120788574\n",
      "Normalized Time (s/MB): 0.9503480303005594\n",
      "Average CPU Usage: 66.1\n",
      "Sample Size: 0.25\n",
      "--------------------------------------------------\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Metrics for sample size 0.125:\n",
      "RMSE: 0.40859825581015946\n",
      "MAPE: 0.1016993570546063\n",
      "R2: 0.19870286725279718\n",
      "MSE: 0.1669525346511045\n",
      "nRMSE: 0.1361994186033865\n",
      "Execution Time (Raw): 67.93962574005127\n",
      "Normalized Time (s/MB): 0.8964555683338055\n",
      "Average CPU Usage: 74.15\n",
      "Sample Size: 0.125\n",
      "--------------------------------------------------\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Metrics for sample size 100:\n",
      "RMSE: 0.36518285043414206\n",
      "MAPE: 0.10330600043137869\n",
      "R2: 0.4870826374953655\n",
      "MSE: 0.13335851425120496\n",
      "nRMSE: 0.12172761681138068\n",
      "Execution Time (Raw): 0.24971675872802734\n",
      "Normalized Time (s/MB): 29.223995535714284\n",
      "Average CPU Usage: 67.65\n",
      "Sample Size: 100\n",
      "--------------------------------------------------\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Metrics for sample size 1000:\n",
      "RMSE: 0.4549615126616046\n",
      "MAPE: 0.1052837493022283\n",
      "R2: 0.07168974995701094\n",
      "MSE: 0.20698997800333543\n",
      "nRMSE: 0.15165383755386821\n",
      "Execution Time (Raw): 0.8067488670349121\n",
      "Normalized Time (s/MB): 9.441266741071429\n",
      "Average CPU Usage: 62.7\n",
      "Sample Size: 1000\n",
      "--------------------------------------------------\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Metrics for sample size 10000:\n",
      "RMSE: 0.4309989993891918\n",
      "MAPE: 0.12036556055148442\n",
      "R2: 0.13365317248928965\n",
      "MSE: 0.18576013747448455\n",
      "nRMSE: 0.1436663331297306\n",
      "Execution Time (Raw): 2.553628444671631\n",
      "Normalized Time (s/MB): 2.988474888392857\n",
      "Average CPU Usage: 68.6\n",
      "Sample Size: 10000\n",
      "--------------------------------------------------\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Metrics for sample size 100000:\n",
      "RMSE: 0.41761526806166394\n",
      "MAPE: 0.1090891199255983\n",
      "R2: 0.14776815597184012\n",
      "MSE: 0.17440251211821542\n",
      "nRMSE: 0.13920508935388798\n",
      "Execution Time (Raw): 9.462998390197754\n",
      "Normalized Time (s/MB): 1.1074411830357143\n",
      "Average CPU Usage: 69.0\n",
      "Sample Size: 100000\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"LOKY_MAX_CPU_COUNT\"] = \"12\"\n",
    "# Define sample sizes\n",
    "sample_sizes = [1.0, 0.5, 0.25, 0.125, 100, 1000, 10000, 100000]\n",
    "\n",
    "# Initialize metrics storage\n",
    "metrics_list = []\n",
    "total_execution_time = 0\n",
    "total_cpu_usage = 0\n",
    "total_memory_usage_MB = 0\n",
    "\n",
    "# Loop through each sample size\n",
    "for size in sample_sizes:\n",
    "    try:\n",
    "        X_train_sample, X_test_sample, y_train_sample, y_test_sample = sample_data(X, y, size)\n",
    "        metrics = calculate_metrics(X_train_sample, X_test_sample, y_train_sample, y_test_sample)\n",
    "        metrics['Sample Size'] = size\n",
    "        metrics_list.append(metrics)\n",
    "\n",
    "        # Accumulate total metrics\n",
    "        total_execution_time += metrics['Execution Time (Raw)']\n",
    "        total_cpu_usage += metrics['Average CPU Usage']\n",
    "        total_memory_usage_MB += X_train_sample.memory_usage(deep=True).sum() / (1024 ** 2)\n",
    "\n",
    "        print(f\"Metrics for sample size {size}:\")\n",
    "        for key, value in metrics.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for sample size {size}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Execution Time for Entire Process (Raw): 21 minutes and 8.74 seconds\n",
      "Total Normalized Execution Time for Entire Process: 1.10740403 seconds per MB\n",
      "Total Average CPU Usage for Entire Process: 63.46%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE</th>\n",
       "      <th>nRMSE</th>\n",
       "      <th>Execution Time (Raw)</th>\n",
       "      <th>Normalized Time (s/MB)</th>\n",
       "      <th>Average CPU Usage</th>\n",
       "      <th>Sample Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.406480</td>\n",
       "      <td>0.103008</td>\n",
       "      <td>0.222855</td>\n",
       "      <td>0.165226</td>\n",
       "      <td>0.135493</td>\n",
       "      <td>722.940482</td>\n",
       "      <td>1.193583</td>\n",
       "      <td>47.10</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.405388</td>\n",
       "      <td>0.100615</td>\n",
       "      <td>0.211245</td>\n",
       "      <td>0.164339</td>\n",
       "      <td>0.135129</td>\n",
       "      <td>320.741982</td>\n",
       "      <td>1.058038</td>\n",
       "      <td>52.40</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.406576</td>\n",
       "      <td>0.100865</td>\n",
       "      <td>0.206616</td>\n",
       "      <td>0.165304</td>\n",
       "      <td>0.135525</td>\n",
       "      <td>144.047941</td>\n",
       "      <td>0.950348</td>\n",
       "      <td>66.10</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.408598</td>\n",
       "      <td>0.101699</td>\n",
       "      <td>0.198703</td>\n",
       "      <td>0.166953</td>\n",
       "      <td>0.136199</td>\n",
       "      <td>67.939626</td>\n",
       "      <td>0.896456</td>\n",
       "      <td>74.15</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.365183</td>\n",
       "      <td>0.103306</td>\n",
       "      <td>0.487083</td>\n",
       "      <td>0.133359</td>\n",
       "      <td>0.121728</td>\n",
       "      <td>0.249717</td>\n",
       "      <td>29.223996</td>\n",
       "      <td>67.65</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.454962</td>\n",
       "      <td>0.105284</td>\n",
       "      <td>0.071690</td>\n",
       "      <td>0.206990</td>\n",
       "      <td>0.151654</td>\n",
       "      <td>0.806749</td>\n",
       "      <td>9.441267</td>\n",
       "      <td>62.70</td>\n",
       "      <td>1000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.430999</td>\n",
       "      <td>0.120366</td>\n",
       "      <td>0.133653</td>\n",
       "      <td>0.185760</td>\n",
       "      <td>0.143666</td>\n",
       "      <td>2.553628</td>\n",
       "      <td>2.988475</td>\n",
       "      <td>68.60</td>\n",
       "      <td>10000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.417615</td>\n",
       "      <td>0.109089</td>\n",
       "      <td>0.147768</td>\n",
       "      <td>0.174403</td>\n",
       "      <td>0.139205</td>\n",
       "      <td>9.462998</td>\n",
       "      <td>1.107441</td>\n",
       "      <td>69.00</td>\n",
       "      <td>100000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       RMSE      MAPE        R2       MSE     nRMSE  Execution Time (Raw)  \\\n",
       "0  0.406480  0.103008  0.222855  0.165226  0.135493            722.940482   \n",
       "1  0.405388  0.100615  0.211245  0.164339  0.135129            320.741982   \n",
       "2  0.406576  0.100865  0.206616  0.165304  0.135525            144.047941   \n",
       "3  0.408598  0.101699  0.198703  0.166953  0.136199             67.939626   \n",
       "4  0.365183  0.103306  0.487083  0.133359  0.121728              0.249717   \n",
       "5  0.454962  0.105284  0.071690  0.206990  0.151654              0.806749   \n",
       "6  0.430999  0.120366  0.133653  0.185760  0.143666              2.553628   \n",
       "7  0.417615  0.109089  0.147768  0.174403  0.139205              9.462998   \n",
       "\n",
       "   Normalized Time (s/MB)  Average CPU Usage  Sample Size  \n",
       "0                1.193583              47.10        1.000  \n",
       "1                1.058038              52.40        0.500  \n",
       "2                0.950348              66.10        0.250  \n",
       "3                0.896456              74.15        0.125  \n",
       "4               29.223996              67.65      100.000  \n",
       "5                9.441267              62.70     1000.000  \n",
       "6                2.988475              68.60    10000.000  \n",
       "7                1.107441              69.00   100000.000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert metrics to DataFrame\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "\n",
    "# Calculate total metrics\n",
    "total_avg_cpu_usage = total_cpu_usage / len(sample_sizes)\n",
    "normalized_total_time = total_execution_time / total_memory_usage_MB\n",
    "\n",
    "# Convert total execution time to minutes and seconds\n",
    "total_minutes = int(total_execution_time // 60)\n",
    "total_seconds = total_execution_time % 60\n",
    "\n",
    "# Display total metrics\n",
    "print(f\"Total Execution Time for Entire Process (Raw): {total_minutes} minutes and {total_seconds:.2f} seconds\")\n",
    "print(f\"Total Normalized Execution Time for Entire Process: {normalized_total_time:.8f} seconds per MB\")\n",
    "print(f\"Total Average CPU Usage for Entire Process: {total_avg_cpu_usage:.2f}%\")\n",
    "\n",
    "# Display the metrics DataFrame\n",
    "metrics_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate and return metrics\n",
    "def calculate_metrics(X_train, X_test, y_train, y_test):\n",
    "    model = xgb.XGBRegressor(random_state=42)\n",
    "\n",
    "    # Define hyperparameters for RandomizedSearchCV\n",
    "    param_distributions = {\n",
    "        'n_estimators': [50, 100, 150],  # Reduced number of trees\n",
    "        'max_depth': [2, 4, 6, 8, 10, 20],  # Shallower trees for faster training\n",
    "        'learning_rate': [0.01, 0.05, 0.1],  # Slightly higher learning rate for quicker convergence\n",
    "        'subsample': [0.8, 1.0],  # Fixed subsample ratio for speed\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],  # Fixed column sample ratio\n",
    "        'gamma': [0, 0.1],  # Reduced regularization to speed up training\n",
    "        'min_child_weight': [1, 3]  # Balanced min_child_weight for regularization\n",
    "    }\n",
    "\n",
    "    random_search = RandomizedSearchCV(model, param_distributions, n_iter=20, cv=5, scoring='neg_mean_squared_error', random_state=42, n_jobs=-1, verbose=2)\n",
    "\n",
    "    start_time = time.time()\n",
    "    start_cpu = psutil.cpu_percent(interval=None)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    end_cpu = psutil.cpu_percent(interval=None)\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calculate time and CPU usage\n",
    "    execution_time = end_time - start_time\n",
    "    avg_cpu_usage = (start_cpu + end_cpu) / 2\n",
    "\n",
    "    y_pred = random_search.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    # Calculate the range of the target variable\n",
    "    target_range = y_train.max() - y_train.min()\n",
    "\n",
    "    # Calculate normalized RMSE (nRMSE)\n",
    "    nrmse = rmse / target_range\n",
    "    \n",
    "    memory_usage_MB = X_train.memory_usage(deep=True).sum() / (1024 ** 2)\n",
    "    normalized_time = execution_time / memory_usage_MB\n",
    "    \n",
    "    return {\n",
    "        'RMSE': rmse,\n",
    "        'MAPE': mape,\n",
    "        'R2': r2,\n",
    "        'MSE': mse,\n",
    "        'nRMSE': nrmse,  # Normalized RMSE\n",
    "        'Execution Time (Raw)': execution_time,  # Raw execution time\n",
    "        'Normalized Time (s/MB)': normalized_time,  # Normalized execution time\n",
    "        'Average CPU Usage': avg_cpu_usage\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LOKY_MAX_CPU_COUNT\"] = \"12\"\n",
    "# Define sample sizes\n",
    "sample_sizes = [1.0, 0.5, 0.25, 0.125, 100, 1000, 10000, 100000]\n",
    "\n",
    "# Initialize metrics storage\n",
    "metrics_list = []\n",
    "total_execution_time = 0\n",
    "total_cpu_usage = 0\n",
    "total_memory_usage_MB = 0\n",
    "\n",
    "# Loop through each sample size\n",
    "for size in sample_sizes:\n",
    "    try:\n",
    "        X_train_sample, X_test_sample, y_train_sample, y_test_sample = sample_data(X, y, size)\n",
    "        metrics = calculate_metrics(X_train_sample, X_test_sample, y_train_sample, y_test_sample)\n",
    "        metrics['Sample Size'] = size\n",
    "        metrics_list.append(metrics)\n",
    "\n",
    "        # Accumulate total metrics\n",
    "        total_execution_time += metrics['Execution Time (Raw)']\n",
    "        total_cpu_usage += metrics['Average CPU Usage']\n",
    "        total_memory_usage_MB += X_train_sample.memory_usage(deep=True).sum() / (1024 ** 2)\n",
    "\n",
    "        print(f\"Metrics for sample size {size}:\")\n",
    "        for key, value in metrics.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for sample size {size}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert metrics to DataFrame\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "\n",
    "# Calculate total metrics\n",
    "total_avg_cpu_usage = total_cpu_usage / len(sample_sizes)\n",
    "normalized_total_time = total_execution_time / total_memory_usage_MB\n",
    "\n",
    "# Convert total execution time to minutes and seconds\n",
    "total_minutes = int(total_execution_time // 60)\n",
    "total_seconds = total_execution_time % 60\n",
    "\n",
    "# Display total metrics\n",
    "print(f\"Total Execution Time for Entire Process (Raw): {total_minutes} minutes and {total_seconds:.2f} seconds\")\n",
    "print(f\"Total Normalized Execution Time for Entire Process: {normalized_total_time:.8f} seconds per MB\")\n",
    "print(f\"Total Average CPU Usage for Entire Process: {total_avg_cpu_usage:.2f}%\")\n",
    "\n",
    "# Display the metrics DataFrame\n",
    "metrics_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
