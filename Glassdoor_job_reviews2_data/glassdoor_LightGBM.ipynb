{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guest01\\AppData\\Local\\Temp\\ipykernel_20140\\4126841228.py:4: DtypeWarning: Columns (5,9,10,11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_sampled = pd.read_csv(\"C:/Users/Guest01/Documents/Manpreet_thesis/Datasets/Glassdoor_job_reviews2/all_reviews.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>status</th>\n",
       "      <th>pros</th>\n",
       "      <th>cons</th>\n",
       "      <th>advice</th>\n",
       "      <th>Recommend</th>\n",
       "      <th>CEO Approval</th>\n",
       "      <th>Business Outlook</th>\n",
       "      <th>Career Opportunities</th>\n",
       "      <th>Compensation and Benefits</th>\n",
       "      <th>Senior Management</th>\n",
       "      <th>Work/Life Balance</th>\n",
       "      <th>Culture &amp; Values</th>\n",
       "      <th>Diversity &amp; Inclusion</th>\n",
       "      <th>firm_link</th>\n",
       "      <th>date</th>\n",
       "      <th>job</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Good</td>\n",
       "      <td>Current Employee, more than 10 years</td>\n",
       "      <td>Knowledge gain of complete  project</td>\n",
       "      <td>Financial growth  and personal growth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>v</td>\n",
       "      <td>o</td>\n",
       "      <td>v</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Reviews/Baja-Steel-and-Fence-Reviews-E5462645.htm</td>\n",
       "      <td>Nov 19, 2022</td>\n",
       "      <td>Manager Design</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Good</td>\n",
       "      <td>Former Employee, less than 1 year</td>\n",
       "      <td>Good work,good work , flexible, support</td>\n",
       "      <td>Good,work, flexible,good support, good team work</td>\n",
       "      <td>NaN</td>\n",
       "      <td>v</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Reviews/Baja-Steel-and-Fence-Reviews-E5462645.htm</td>\n",
       "      <td>Jan 29, 2022</td>\n",
       "      <td>Anonymous Employee</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Supervising the manufacturing the processes, e...</td>\n",
       "      <td>Current Employee, more than 1 year</td>\n",
       "      <td>This company is a best opportunity for me to l...</td>\n",
       "      <td>Monthly Target work,Maintain production schedu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>v</td>\n",
       "      <td>o</td>\n",
       "      <td>v</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Reviews/Baja-Steel-and-Fence-Reviews-E5462645.htm</td>\n",
       "      <td>Aug 12, 2021</td>\n",
       "      <td>Production Engineer</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>terrible</td>\n",
       "      <td>Current Employee, more than 1 year</td>\n",
       "      <td>I wish there were some to list</td>\n",
       "      <td>too many to list here</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.glassdoor.com/Reviews/Calgary-Flam...</td>\n",
       "      <td>Sep 24, 2020</td>\n",
       "      <td>Senior Account Executive</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>It could be so good, but it isn’t</td>\n",
       "      <td>Current Employee, more than 3 years</td>\n",
       "      <td>Fast Paced. Endless challenges. Inclusive envi...</td>\n",
       "      <td>The biggest perk of the job provides no value ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>https://www.glassdoor.com/Reviews/Calgary-Flam...</td>\n",
       "      <td>Mar 25, 2023</td>\n",
       "      <td>Assistant Manager</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                              title  \\\n",
       "0     5.0                                               Good   \n",
       "1     4.0                                               Good   \n",
       "2     4.0  Supervising the manufacturing the processes, e...   \n",
       "3     1.0                                           terrible   \n",
       "4     4.0                  It could be so good, but it isn’t   \n",
       "\n",
       "                                 status  \\\n",
       "0  Current Employee, more than 10 years   \n",
       "1     Former Employee, less than 1 year   \n",
       "2    Current Employee, more than 1 year   \n",
       "3    Current Employee, more than 1 year   \n",
       "4   Current Employee, more than 3 years   \n",
       "\n",
       "                                                pros  \\\n",
       "0                Knowledge gain of complete  project   \n",
       "1            Good work,good work , flexible, support   \n",
       "2  This company is a best opportunity for me to l...   \n",
       "3                     I wish there were some to list   \n",
       "4  Fast Paced. Endless challenges. Inclusive envi...   \n",
       "\n",
       "                                                cons advice Recommend  \\\n",
       "0              Financial growth  and personal growth    NaN         v   \n",
       "1   Good,work, flexible,good support, good team work    NaN         v   \n",
       "2  Monthly Target work,Maintain production schedu...    NaN         v   \n",
       "3                              too many to list here    NaN         x   \n",
       "4  The biggest perk of the job provides no value ...    NaN         o   \n",
       "\n",
       "  CEO Approval Business Outlook Career Opportunities  \\\n",
       "0            o                v                    3   \n",
       "1            o                o                    4   \n",
       "2            o                v                    2   \n",
       "3            x                x                  1.0   \n",
       "4            o                o                  3.0   \n",
       "\n",
       "  Compensation and Benefits Senior Management Work/Life Balance  \\\n",
       "0                         3                 3                 3   \n",
       "1                         4                 4                 4   \n",
       "2                         3                 2                 2   \n",
       "3                       3.0               1.0               3.0   \n",
       "4                       3.0               3.0               1.0   \n",
       "\n",
       "   Culture & Values  Diversity & Inclusion  \\\n",
       "0               3.0                    3.0   \n",
       "1               4.0                    4.0   \n",
       "2               2.0                    2.0   \n",
       "3               1.0                    NaN   \n",
       "4               4.0                    5.0   \n",
       "\n",
       "                                           firm_link           date  \\\n",
       "0  Reviews/Baja-Steel-and-Fence-Reviews-E5462645.htm  Nov 19, 2022    \n",
       "1  Reviews/Baja-Steel-and-Fence-Reviews-E5462645.htm  Jan 29, 2022    \n",
       "2  Reviews/Baja-Steel-and-Fence-Reviews-E5462645.htm  Aug 12, 2021    \n",
       "3  https://www.glassdoor.com/Reviews/Calgary-Flam...  Sep 24, 2020    \n",
       "4  https://www.glassdoor.com/Reviews/Calgary-Flam...  Mar 25, 2023    \n",
       "\n",
       "                         job  index  \n",
       "0             Manager Design    NaN  \n",
       "1         Anonymous Employee    NaN  \n",
       "2        Production Engineer    NaN  \n",
       "3   Senior Account Executive    NaN  \n",
       "4          Assistant Manager    NaN  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df_sampled = pd.read_csv(\"C:/Users/Guest01/Documents/Manpreet_thesis/Datasets/Glassdoor_job_reviews2/all_reviews.csv\")\n",
    "\n",
    "# Downcast numerical columns to save memory\n",
    "def downcast(df):\n",
    "    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n",
    "    int_cols = [c for c in df if df[c].dtype == \"int64\"]\n",
    "    df[float_cols] = df[float_cols].astype(\"float32\")\n",
    "    df[int_cols] = df[int_cols].astype(\"int32\")\n",
    "    return df\n",
    "\n",
    "df_sampled = downcast(df_sampled)\n",
    "df_sampled.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pros                         0\n",
       "cons                         0\n",
       "Recommend                    0\n",
       "Career Opportunities         0\n",
       "Compensation and Benefits    0\n",
       "Senior Management            0\n",
       "Work/Life Balance            0\n",
       "Culture & Values             0\n",
       "Diversity & Inclusion        0\n",
       "job                          0\n",
       "status                       0\n",
       "rating                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of relevant features\n",
    "relevant_features = [\n",
    "    'pros', 'cons', 'Recommend', 'Career Opportunities', 'Compensation and Benefits', \n",
    "    'Senior Management', 'Work/Life Balance', 'Culture & Values', 'Diversity & Inclusion', \n",
    "    'job', 'status'\n",
    "]\n",
    "\n",
    "# Fill null values with mode for categorical columns and median for numerical columns\n",
    "def fill_nulls(df, features):\n",
    "    for column in features:\n",
    "        if df[column].dtype == 'object':\n",
    "            df[column] = df[column].fillna(df[column].mode()[0])\n",
    "        else:\n",
    "            df[column] = df[column].fillna(df[column].median())\n",
    "    return df\n",
    "\n",
    "df_sampled = fill_nulls(df_sampled, relevant_features + ['rating'])  # Apply to relevant features and 'rating'\n",
    "\n",
    "# Check for any remaining null values in relevant features\n",
    "df_sampled[relevant_features + ['rating']].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency encoding for categorical variables\n",
    "def frequency_encoding(df, columns):\n",
    "    df_copy = df.copy()  # Create a copy of the DataFrame to avoid the warning\n",
    "    for column in columns:\n",
    "        # Generate the frequency encoding (i.e., percentage frequency of each unique value)\n",
    "        freq = df_copy[column].value_counts() / len(df_copy)\n",
    "        # Map the original column with its frequency encoding\n",
    "        df_copy[column] = df_copy[column].map(freq).astype('float32')  # Explicitly cast to float32 to avoid dtype issues\n",
    "    return df_copy\n",
    "\n",
    "# Apply frequency encoding to the relevant non-numeric columns\n",
    "df_sampled = frequency_encoding(df_sampled, relevant_features)\n",
    "\n",
    "# Downcast again to save memory\n",
    "df_sampled = downcast(df_sampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric columns in X: Index([], dtype='object')\n",
      "Shape of X: (9901889, 11)\n",
      "Shape of y: (9901889,)\n"
     ]
    }
   ],
   "source": [
    "# Define X and y\n",
    "X = df_sampled[relevant_features]  # Use only relevant features for X\n",
    "y = df_sampled['rating']  # Target variable\n",
    "\n",
    "# Check for non-numeric columns in X\n",
    "non_numeric_columns_in_X = X.select_dtypes(include=['object', 'category']).columns\n",
    "print(\"Non-numeric columns in X:\", non_numeric_columns_in_X)\n",
    "\n",
    "# Print the shapes of X and y\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of y:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to sample data\n",
    "def sample_data(X, y, sample_size):\n",
    "    if isinstance(sample_size, float):\n",
    "        if 0 < sample_size < 1.0:\n",
    "            return train_test_split(X, y, test_size=0.2, train_size=sample_size, random_state=42)\n",
    "        elif sample_size == 1.0:\n",
    "            return train_test_split(X, y, test_size=0.2, train_size=None, random_state=42)  # Fix for 1.0 sample size\n",
    "        else:\n",
    "            raise ValueError(\"sample_size as float must be in the range (0.0, 1.0) or equal to 1.0.\")\n",
    "    elif isinstance(sample_size, int):\n",
    "        if sample_size > len(X):\n",
    "            raise ValueError(f\"sample_size {sample_size} exceeds the number of available samples {len(X)}.\")\n",
    "        sampled_X = X.sample(n=sample_size, random_state=42)\n",
    "        sampled_y = y.loc[sampled_X.index]\n",
    "        return train_test_split(sampled_X, sampled_y, test_size=0.2, random_state=42)\n",
    "    else:\n",
    "        raise ValueError(\"sample_size must be a float or an integer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "import numpy as np\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "# Function to calculate and return metrics for LightGBM\n",
    "def calculate_metrics(X_train, X_test, y_train, y_test):\n",
    "    # Initialize LightGBM Regressor\n",
    "    lgbm = lgb.LGBMRegressor(random_state=42)\n",
    "\n",
    "    # Define hyperparameters for RandomizedSearchCV\n",
    "    param_distributions = {\n",
    "        'n_estimators': [50, 100],  # Number of boosting rounds\n",
    "        'learning_rate': [0.01, 0.05, 0.1],  # Learning rate\n",
    "        'max_depth': [10, 20, 30],  # Maximum depth, \n",
    "        'num_leaves': [31, 40, 50],  # Maximum number of leaves in one tree\n",
    "        'min_child_samples': [5, 10, 20],  # Minimum number of samples in one leaf\n",
    "        'subsample': [0.8, 0.9, 1.0],  # Fraction of data to be used for each tree\n",
    "        'colsample_bytree': [0.8, 0.9, 1.0],  # Fraction of features used for each tree\n",
    "    }\n",
    "\n",
    "    random_search = RandomizedSearchCV(lgbm, param_distributions, n_iter=10, cv=5, scoring='neg_mean_squared_error', random_state=42, n_jobs=-1)\n",
    "\n",
    "    start_time = time.time()\n",
    "    start_cpu = psutil.cpu_percent(interval=None)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    end_cpu = psutil.cpu_percent(interval=None)\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calculate time and CPU usage\n",
    "    execution_time = end_time - start_time\n",
    "    avg_cpu_usage = (start_cpu + end_cpu) / 2\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = random_search.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Calculate normalized RMSE (nRMSE)\n",
    "    target_range = y_train.max() - y_train.min()\n",
    "    nrmse = rmse / target_range\n",
    "\n",
    "    # Memory usage\n",
    "    memory_usage_MB = X_train.memory_usage(deep=True).sum() / (1024 ** 2)\n",
    "    normalized_time = execution_time / memory_usage_MB\n",
    "\n",
    "    return {\n",
    "        'RMSE': rmse,\n",
    "        'MAPE': mape,\n",
    "        'R2': r2,\n",
    "        'nRMSE': nrmse,  # Normalized RMSE\n",
    "        'Execution Time (Raw)': execution_time,  # Raw execution time\n",
    "        'Normalized Time (s/MB)': normalized_time,  # Normalized execution time\n",
    "        'Average CPU Usage': avg_cpu_usage\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.283614 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 720\n",
      "[LightGBM] [Info] Number of data points in the train set: 7921511, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 3.557866\n",
      "Metrics for sample size 1.0:\n",
      "RMSE: 0.6996663686187731\n",
      "MAPE: 0.19921380380638473\n",
      "R2: 0.6865299022965287\n",
      "nRMSE: 0.17491659215469327\n",
      "Execution Time (Raw): 1057.4562313556671\n",
      "Normalized Time (s/MB): 2.6918505273173263\n",
      "Average CPU Usage: 56.9\n",
      "Sample Size: 1.0\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061128 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 727\n",
      "[LightGBM] [Info] Number of data points in the train set: 4950944, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 3.558041\n",
      "Metrics for sample size 0.5:\n",
      "RMSE: 0.6995728844277076\n",
      "MAPE: 0.19927382345554726\n",
      "R2: 0.6866136637636999\n",
      "nRMSE: 0.1748932211069269\n",
      "Execution Time (Raw): 699.3275244235992\n",
      "Normalized Time (s/MB): 2.8483226099056913\n",
      "Average CPU Usage: 70.55\n",
      "Sample Size: 0.5\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.087978 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 724\n",
      "[LightGBM] [Info] Number of data points in the train set: 2475472, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 3.557519\n",
      "Metrics for sample size 0.25:\n",
      "RMSE: 0.6998433204680217\n",
      "MAPE: 0.19930986627589484\n",
      "R2: 0.6863713234930384\n",
      "nRMSE: 0.17496083011700542\n",
      "Execution Time (Raw): 321.45513343811035\n",
      "Normalized Time (s/MB): 2.618538217544589\n",
      "Average CPU Usage: 74.3\n",
      "Sample Size: 0.25\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014558 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 719\n",
      "[LightGBM] [Info] Number of data points in the train set: 1237736, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 3.559621\n",
      "Metrics for sample size 0.125:\n",
      "RMSE: 0.7000770219812887\n",
      "MAPE: 0.19950330773766542\n",
      "R2: 0.6861618259323974\n",
      "nRMSE: 0.17501925549532218\n",
      "Execution Time (Raw): 146.35375213623047\n",
      "Normalized Time (s/MB): 2.384363187178973\n",
      "Average CPU Usage: 74.65\n",
      "Sample Size: 0.125\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000138 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 89\n",
      "[LightGBM] [Info] Number of data points in the train set: 80, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 3.550000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Metrics for sample size 100:\n",
      "RMSE: 0.5873900040618032\n",
      "MAPE: 0.16647276492180613\n",
      "R2: 0.771505286839917\n",
      "nRMSE: 0.1468475010154508\n",
      "Execution Time (Raw): 1.0085272789001465\n",
      "Normalized Time (s/MB): 254.2109375\n",
      "Average CPU Usage: 73.6\n",
      "Sample Size: 100\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000145 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 364\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 3.585000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Metrics for sample size 1000:\n",
      "RMSE: 0.8152600012055542\n",
      "MAPE: 0.26230867693837945\n",
      "R2: 0.5935117915933703\n",
      "nRMSE: 0.20381500030138855\n",
      "Execution Time (Raw): 2.873196840286255\n",
      "Normalized Time (s/MB): 72.42224158653846\n",
      "Average CPU Usage: 65.15\n",
      "Sample Size: 1000\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000331 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 519\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 3.561125\n",
      "Metrics for sample size 10000:\n",
      "RMSE: 0.7395515227898561\n",
      "MAPE: 0.20948465758345763\n",
      "R2: 0.6351684116120008\n",
      "nRMSE: 0.18488788069746404\n",
      "Execution Time (Raw): 4.469184398651123\n",
      "Normalized Time (s/MB): 11.265094951923077\n",
      "Average CPU Usage: 73.05\n",
      "Sample Size: 10000\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001178 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 712\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 3.558113\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Metrics for sample size 100000:\n",
      "RMSE: 0.7123885875044038\n",
      "MAPE: 0.20608890799004967\n",
      "R2: 0.6790561228649541\n",
      "nRMSE: 0.17809714687610095\n",
      "Execution Time (Raw): 15.507784128189087\n",
      "Normalized Time (s/MB): 3.9089159254807693\n",
      "Average CPU Usage: 61.5\n",
      "Sample Size: 100000\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import gc  # Garbage Collector\n",
    "\n",
    "# Define sample sizes\n",
    "sample_sizes = [1.0, 0.5, 0.25, 0.125, 100, 1000, 10000, 100000]  \n",
    "\n",
    "# Initialize metrics storage\n",
    "metrics_list = []\n",
    "total_execution_time = 0\n",
    "total_cpu_usage = 0\n",
    "total_memory_usage_MB = 0\n",
    "\n",
    "# Loop through each sample size\n",
    "for size in sample_sizes:\n",
    "    try:\n",
    "        # Sample data based on the defined sizes\n",
    "        X_train_sample, X_test_sample, y_train_sample, y_test_sample = sample_data(X, y, size)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics = calculate_metrics(X_train_sample, X_test_sample, y_train_sample, y_test_sample)\n",
    "        metrics['Sample Size'] = size\n",
    "        metrics_list.append(metrics)\n",
    "\n",
    "        # Call garbage collection after each iteration to free up memory\n",
    "        gc.collect()\n",
    "\n",
    "        # Accumulate total metrics\n",
    "        total_execution_time += metrics['Execution Time (Raw)']\n",
    "        total_cpu_usage += metrics['Average CPU Usage']\n",
    "        total_memory_usage_MB += X_train_sample.memory_usage(deep=True).sum() / (1024 ** 2)\n",
    "\n",
    "        print(f\"Metrics for sample size {size}:\")\n",
    "        for key, value in metrics.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for sample size {size}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Execution Time for Entire Process (Raw): 37 minutes and 28.45 seconds\n",
      "Total Normalized Execution Time for Entire Process: 2.71910590 seconds per MB\n",
      "Total Average CPU Usage for Entire Process: 68.71%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>R2</th>\n",
       "      <th>nRMSE</th>\n",
       "      <th>Execution Time (Raw)</th>\n",
       "      <th>Normalized Time (s/MB)</th>\n",
       "      <th>Average CPU Usage</th>\n",
       "      <th>Sample Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.699666</td>\n",
       "      <td>0.199214</td>\n",
       "      <td>0.686530</td>\n",
       "      <td>0.174917</td>\n",
       "      <td>1057.456231</td>\n",
       "      <td>2.691851</td>\n",
       "      <td>56.90</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.699573</td>\n",
       "      <td>0.199274</td>\n",
       "      <td>0.686614</td>\n",
       "      <td>0.174893</td>\n",
       "      <td>699.327524</td>\n",
       "      <td>2.848323</td>\n",
       "      <td>70.55</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.699843</td>\n",
       "      <td>0.199310</td>\n",
       "      <td>0.686371</td>\n",
       "      <td>0.174961</td>\n",
       "      <td>321.455133</td>\n",
       "      <td>2.618538</td>\n",
       "      <td>74.30</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.700077</td>\n",
       "      <td>0.199503</td>\n",
       "      <td>0.686162</td>\n",
       "      <td>0.175019</td>\n",
       "      <td>146.353752</td>\n",
       "      <td>2.384363</td>\n",
       "      <td>74.65</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.587390</td>\n",
       "      <td>0.166473</td>\n",
       "      <td>0.771505</td>\n",
       "      <td>0.146848</td>\n",
       "      <td>1.008527</td>\n",
       "      <td>254.210938</td>\n",
       "      <td>73.60</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.815260</td>\n",
       "      <td>0.262309</td>\n",
       "      <td>0.593512</td>\n",
       "      <td>0.203815</td>\n",
       "      <td>2.873197</td>\n",
       "      <td>72.422242</td>\n",
       "      <td>65.15</td>\n",
       "      <td>1000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.739552</td>\n",
       "      <td>0.209485</td>\n",
       "      <td>0.635168</td>\n",
       "      <td>0.184888</td>\n",
       "      <td>4.469184</td>\n",
       "      <td>11.265095</td>\n",
       "      <td>73.05</td>\n",
       "      <td>10000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.712389</td>\n",
       "      <td>0.206089</td>\n",
       "      <td>0.679056</td>\n",
       "      <td>0.178097</td>\n",
       "      <td>15.507784</td>\n",
       "      <td>3.908916</td>\n",
       "      <td>61.50</td>\n",
       "      <td>100000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       RMSE      MAPE        R2     nRMSE  Execution Time (Raw)  \\\n",
       "0  0.699666  0.199214  0.686530  0.174917           1057.456231   \n",
       "1  0.699573  0.199274  0.686614  0.174893            699.327524   \n",
       "2  0.699843  0.199310  0.686371  0.174961            321.455133   \n",
       "3  0.700077  0.199503  0.686162  0.175019            146.353752   \n",
       "4  0.587390  0.166473  0.771505  0.146848              1.008527   \n",
       "5  0.815260  0.262309  0.593512  0.203815              2.873197   \n",
       "6  0.739552  0.209485  0.635168  0.184888              4.469184   \n",
       "7  0.712389  0.206089  0.679056  0.178097             15.507784   \n",
       "\n",
       "   Normalized Time (s/MB)  Average CPU Usage  Sample Size  \n",
       "0                2.691851              56.90        1.000  \n",
       "1                2.848323              70.55        0.500  \n",
       "2                2.618538              74.30        0.250  \n",
       "3                2.384363              74.65        0.125  \n",
       "4              254.210938              73.60      100.000  \n",
       "5               72.422242              65.15     1000.000  \n",
       "6               11.265095              73.05    10000.000  \n",
       "7                3.908916              61.50   100000.000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert metrics to DataFrame\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "\n",
    "# Calculate total metrics\n",
    "total_avg_cpu_usage = total_cpu_usage / len(sample_sizes)\n",
    "normalized_total_time = total_execution_time / total_memory_usage_MB\n",
    "\n",
    "# Convert total execution time to minutes and seconds\n",
    "total_minutes = int(total_execution_time // 60)\n",
    "total_seconds = total_execution_time % 60\n",
    "\n",
    "# Display total metrics\n",
    "print(f\"Total Execution Time for Entire Process (Raw): {total_minutes} minutes and {total_seconds:.2f} seconds\")\n",
    "print(f\"Total Normalized Execution Time for Entire Process: {normalized_total_time:.8f} seconds per MB\")\n",
    "print(f\"Total Average CPU Usage for Entire Process: {total_avg_cpu_usage:.2f}%\")\n",
    "\n",
    "# Display the metrics DataFrame\n",
    "metrics_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "import numpy as np\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "# Function to calculate and return metrics for LightGBM Regressor\n",
    "def calculate_metrics(X_train, X_test, y_train, y_test):\n",
    "    gbm = lgb.LGBMRegressor(random_state=42)\n",
    "\n",
    "    # Define hyperparameters for RandomizedSearchCV\n",
    "    param_distributions = {\n",
    "        'n_estimators': [50, 75],  # Number of boosting stages\n",
    "        'learning_rate': [0.05, 0.1],  # Step size shrinkage\n",
    "        'max_depth': [3, 5, 7],  # Maximum depth of individual trees\n",
    "        'min_child_samples': [20, 30],  # Minimum number of samples in a leaf\n",
    "        'subsample': [0.8, 0.9],  # Fraction of samples used for training\n",
    "        'colsample_bytree': [0.8, 1.0],  # Fraction of features used per tree\n",
    "        'force_col_wise': [True]\n",
    "    }\n",
    "\n",
    "    random_search = RandomizedSearchCV(gbm, param_distributions, n_iter=10, cv=3, scoring='neg_mean_squared_error', random_state=42, n_jobs=-1)\n",
    "\n",
    "    start_time = time.time()\n",
    "    start_cpu = psutil.cpu_percent(interval=None)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    end_cpu = psutil.cpu_percent(interval=None)\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calculate time and CPU usage\n",
    "    execution_time = end_time - start_time\n",
    "    avg_cpu_usage = (start_cpu + end_cpu) / 2\n",
    "\n",
    "    y_pred = random_search.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Calculate the range of the target variable\n",
    "    target_range = y_train.max() - y_train.min()\n",
    "\n",
    "    # Calculate normalized RMSE (nRMSE)\n",
    "    nrmse = rmse / target_range\n",
    "    \n",
    "    memory_usage_MB = X_train.memory_usage(deep=True).sum() / (1024 ** 2)\n",
    "    normalized_time = execution_time / memory_usage_MB\n",
    "    \n",
    "    return {\n",
    "        'RMSE': rmse,\n",
    "        'MAPE': mape,\n",
    "        'R2': r2,\n",
    "        'nRMSE': nrmse,  # Normalized RMSE\n",
    "        'Execution Time (Raw)': execution_time,  # Raw execution time\n",
    "        'Normalized Time (s/MB)': normalized_time,  # Normalized execution time\n",
    "        'Average CPU Usage': avg_cpu_usage\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 720\n",
      "[LightGBM] [Info] Number of data points in the train set: 7921511, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 3.557866\n",
      "Metrics for sample size 1.0:\n",
      "RMSE: 0.7052148938193478\n",
      "MAPE: 0.2023657006619458\n",
      "R2: 0.681538399663183\n",
      "nRMSE: 0.17630372345483694\n",
      "Execution Time (Raw): 242.56266832351685\n",
      "Normalized Time (s/MB): 0.6174652219856696\n",
      "Average CPU Usage: 50.95\n",
      "Sample Size: 1.0\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 727\n",
      "[LightGBM] [Info] Number of data points in the train set: 4950944, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 3.558041\n",
      "Metrics for sample size 0.5:\n",
      "RMSE: 0.7050431513252312\n",
      "MAPE: 0.20223110594055685\n",
      "R2: 0.681693492047653\n",
      "nRMSE: 0.1762607878313078\n",
      "Execution Time (Raw): 143.38859748840332\n",
      "Normalized Time (s/MB): 0.5840138847180535\n",
      "Average CPU Usage: 63.0\n",
      "Sample Size: 0.5\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 724\n",
      "[LightGBM] [Info] Number of data points in the train set: 2475472, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 3.557519\n",
      "Metrics for sample size 0.25:\n",
      "RMSE: 0.7051266149068524\n",
      "MAPE: 0.2024231402708851\n",
      "R2: 0.6816181248203599\n",
      "nRMSE: 0.1762816537267131\n",
      "Execution Time (Raw): 70.13535332679749\n",
      "Normalized Time (s/MB): 0.5713148865378773\n",
      "Average CPU Usage: 66.6\n",
      "Sample Size: 0.25\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 719\n",
      "[LightGBM] [Info] Number of data points in the train set: 1237736, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 3.559621\n",
      "Metrics for sample size 0.125:\n",
      "RMSE: 0.705378627754269\n",
      "MAPE: 0.2023949919014293\n",
      "R2: 0.6813905042498182\n",
      "nRMSE: 0.17634465693856724\n",
      "Execution Time (Raw): 34.07953119277954\n",
      "Normalized Time (s/MB): 0.5552162375498491\n",
      "Average CPU Usage: 64.9\n",
      "Sample Size: 0.125\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 72\n",
      "[LightGBM] [Info] Number of data points in the train set: 80, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 3.550000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Metrics for sample size 100:\n",
      "RMSE: 0.8096953675599757\n",
      "MAPE: 0.25266526303886633\n",
      "R2: 0.565823451491335\n",
      "nRMSE: 0.20242384188999393\n",
      "Execution Time (Raw): 0.1995687484741211\n",
      "Normalized Time (s/MB): 50.30360576923077\n",
      "Average CPU Usage: 69.85\n",
      "Sample Size: 100\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 364\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 3.585000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Metrics for sample size 1000:\n",
      "RMSE: 0.8049942549614828\n",
      "MAPE: 0.2472341616544223\n",
      "R2: 0.6036843309149331\n",
      "nRMSE: 0.2012485637403707\n",
      "Execution Time (Raw): 0.43885135650634766\n",
      "Normalized Time (s/MB): 11.061754807692308\n",
      "Average CPU Usage: 62.2\n",
      "Sample Size: 1000\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 519\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 3.561125\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Metrics for sample size 10000:\n",
      "RMSE: 0.7391081508264813\n",
      "MAPE: 0.20975548907382932\n",
      "R2: 0.6356057242402288\n",
      "nRMSE: 0.18477703770662032\n",
      "Execution Time (Raw): 0.8182799816131592\n",
      "Normalized Time (s/MB): 2.062569110576923\n",
      "Average CPU Usage: 63.4\n",
      "Sample Size: 10000\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 712\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 3.558113\n",
      "Metrics for sample size 100000:\n",
      "RMSE: 0.7143024368900759\n",
      "MAPE: 0.20753092488587055\n",
      "R2: 0.6773293593094503\n",
      "nRMSE: 0.17857560922251897\n",
      "Execution Time (Raw): 2.977358818054199\n",
      "Normalized Time (s/MB): 0.7504776442307692\n",
      "Average CPU Usage: 59.2\n",
      "Sample Size: 100000\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import gc  # Garbage Collector\n",
    "\n",
    "# Define sample sizes\n",
    "sample_sizes = [1.0, 0.5, 0.25, 0.125, 100, 1000, 10000, 100000]  \n",
    "\n",
    "# Initialize metrics storage\n",
    "metrics_list = []\n",
    "total_execution_time = 0\n",
    "total_cpu_usage = 0\n",
    "total_memory_usage_MB = 0\n",
    "\n",
    "# Loop through each sample size\n",
    "for size in sample_sizes:\n",
    "    try:\n",
    "        # Sample data based on the defined sizes\n",
    "        X_train_sample, X_test_sample, y_train_sample, y_test_sample = sample_data(X, y, size)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics = calculate_metrics(X_train_sample, X_test_sample, y_train_sample, y_test_sample)\n",
    "        metrics['Sample Size'] = size\n",
    "        metrics_list.append(metrics)\n",
    "\n",
    "        # Call garbage collection after each iteration to free up memory\n",
    "        gc.collect()\n",
    "\n",
    "        # Accumulate total metrics\n",
    "        total_execution_time += metrics['Execution Time (Raw)']\n",
    "        total_cpu_usage += metrics['Average CPU Usage']\n",
    "        total_memory_usage_MB += X_train_sample.memory_usage(deep=True).sum() / (1024 ** 2)\n",
    "\n",
    "        print(f\"Metrics for sample size {size}:\")\n",
    "        for key, value in metrics.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for sample size {size}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Execution Time for Entire Process (Raw): 8 minutes and 14.60 seconds\n",
      "Total Normalized Execution Time for Entire Process: 0.59813185 seconds per MB\n",
      "Total Average CPU Usage for Entire Process: 62.51%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>R2</th>\n",
       "      <th>nRMSE</th>\n",
       "      <th>Execution Time (Raw)</th>\n",
       "      <th>Normalized Time (s/MB)</th>\n",
       "      <th>Average CPU Usage</th>\n",
       "      <th>Sample Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.705215</td>\n",
       "      <td>0.202366</td>\n",
       "      <td>0.681538</td>\n",
       "      <td>0.176304</td>\n",
       "      <td>242.562668</td>\n",
       "      <td>0.617465</td>\n",
       "      <td>50.95</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.705043</td>\n",
       "      <td>0.202231</td>\n",
       "      <td>0.681693</td>\n",
       "      <td>0.176261</td>\n",
       "      <td>143.388597</td>\n",
       "      <td>0.584014</td>\n",
       "      <td>63.00</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.705127</td>\n",
       "      <td>0.202423</td>\n",
       "      <td>0.681618</td>\n",
       "      <td>0.176282</td>\n",
       "      <td>70.135353</td>\n",
       "      <td>0.571315</td>\n",
       "      <td>66.60</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.705379</td>\n",
       "      <td>0.202395</td>\n",
       "      <td>0.681391</td>\n",
       "      <td>0.176345</td>\n",
       "      <td>34.079531</td>\n",
       "      <td>0.555216</td>\n",
       "      <td>64.90</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.809695</td>\n",
       "      <td>0.252665</td>\n",
       "      <td>0.565823</td>\n",
       "      <td>0.202424</td>\n",
       "      <td>0.199569</td>\n",
       "      <td>50.303606</td>\n",
       "      <td>69.85</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.804994</td>\n",
       "      <td>0.247234</td>\n",
       "      <td>0.603684</td>\n",
       "      <td>0.201249</td>\n",
       "      <td>0.438851</td>\n",
       "      <td>11.061755</td>\n",
       "      <td>62.20</td>\n",
       "      <td>1000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.739108</td>\n",
       "      <td>0.209755</td>\n",
       "      <td>0.635606</td>\n",
       "      <td>0.184777</td>\n",
       "      <td>0.818280</td>\n",
       "      <td>2.062569</td>\n",
       "      <td>63.40</td>\n",
       "      <td>10000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.714302</td>\n",
       "      <td>0.207531</td>\n",
       "      <td>0.677329</td>\n",
       "      <td>0.178576</td>\n",
       "      <td>2.977359</td>\n",
       "      <td>0.750478</td>\n",
       "      <td>59.20</td>\n",
       "      <td>100000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       RMSE      MAPE        R2     nRMSE  Execution Time (Raw)  \\\n",
       "0  0.705215  0.202366  0.681538  0.176304            242.562668   \n",
       "1  0.705043  0.202231  0.681693  0.176261            143.388597   \n",
       "2  0.705127  0.202423  0.681618  0.176282             70.135353   \n",
       "3  0.705379  0.202395  0.681391  0.176345             34.079531   \n",
       "4  0.809695  0.252665  0.565823  0.202424              0.199569   \n",
       "5  0.804994  0.247234  0.603684  0.201249              0.438851   \n",
       "6  0.739108  0.209755  0.635606  0.184777              0.818280   \n",
       "7  0.714302  0.207531  0.677329  0.178576              2.977359   \n",
       "\n",
       "   Normalized Time (s/MB)  Average CPU Usage  Sample Size  \n",
       "0                0.617465              50.95        1.000  \n",
       "1                0.584014              63.00        0.500  \n",
       "2                0.571315              66.60        0.250  \n",
       "3                0.555216              64.90        0.125  \n",
       "4               50.303606              69.85      100.000  \n",
       "5               11.061755              62.20     1000.000  \n",
       "6                2.062569              63.40    10000.000  \n",
       "7                0.750478              59.20   100000.000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert metrics to DataFrame\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "\n",
    "# Calculate total metrics\n",
    "total_avg_cpu_usage = total_cpu_usage / len(sample_sizes)\n",
    "normalized_total_time = total_execution_time / total_memory_usage_MB\n",
    "\n",
    "# Convert total execution time to minutes and seconds\n",
    "total_minutes = int(total_execution_time // 60)\n",
    "total_seconds = total_execution_time % 60\n",
    "\n",
    "# Display total metrics\n",
    "print(f\"Total Execution Time for Entire Process (Raw): {total_minutes} minutes and {total_seconds:.2f} seconds\")\n",
    "print(f\"Total Normalized Execution Time for Entire Process: {normalized_total_time:.8f} seconds per MB\")\n",
    "print(f\"Total Average CPU Usage for Entire Process: {total_avg_cpu_usage:.2f}%\")\n",
    "\n",
    "# Display the metrics DataFrame\n",
    "metrics_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
