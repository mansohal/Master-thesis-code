{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  anime_id  my_score  score  scored_by gender  \\\n",
      "0        1        21         9   8.54     423868   Male   \n",
      "1        1        48         7   7.09      61485   Male   \n",
      "2        1       320         5   6.66      18934   Male   \n",
      "3        1        49         8   7.38      20930   Male   \n",
      "4        1       304         8   7.63      18571   Male   \n",
      "\n",
      "              Anime Title  rating  \n",
      "0               One Piece       9  \n",
      "1             .hack//Sign       7  \n",
      "2                  A Kite       5  \n",
      "3        Aa! Megami-sama!       8  \n",
      "4  Aa! Megami-sama! Movie       8  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to downcast numeric columns\n",
    "def downcast(df):\n",
    "    for col in df.select_dtypes(include=['int']).columns:\n",
    "        df.loc[:, col] = pd.to_numeric(df[col], downcast='integer')\n",
    "    for col in df.select_dtypes(include=['float']).columns:\n",
    "        df.loc[:, col] = pd.to_numeric(df[col], downcast='float')\n",
    "    return df\n",
    "\n",
    "# Load the datasets with only the required columns\n",
    "df1 = pd.read_csv('C:/Users/Guest01/Documents/dataset_anime/archive/final_animedataset.csv', usecols=['user_id', 'anime_id', 'my_score', 'score', 'scored_by', 'gender'])\n",
    "df2 = pd.read_csv('C:/Users/Guest01/Documents/dataset_anime/archive/users-score-2023.csv', usecols=['user_id', 'anime_id', 'Anime Title', 'rating'])\n",
    "\n",
    "# Merge the datasets on user_id and anime_id\n",
    "merged_df = pd.merge(df2, df1, on=['user_id', 'anime_id'])\n",
    "\n",
    "# Select the necessary columns for the final DataFrame\n",
    "final_df = merged_df[['user_id', 'anime_id', 'my_score', 'score', 'scored_by', 'gender', 'Anime Title', 'rating']]\n",
    "\n",
    "# Downcast numeric columns\n",
    "final_df = downcast(final_df)\n",
    "\n",
    "# Display the first few rows to check the data\n",
    "print(final_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guest01\\AppData\\Local\\Temp\\ipykernel_19764\\2635680959.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  final_df['score'].fillna(final_df['score'].mean(), inplace=True)\n",
      "C:\\Users\\Guest01\\AppData\\Local\\Temp\\ipykernel_19764\\2635680959.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['score'].fillna(final_df['score'].mean(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  anime_id  my_score  score  scored_by    gender  Anime Title  \\\n",
      "0        1        21         9   8.54     423868  7.590573     8.596731   \n",
      "1        1        48         7   7.09      61485  7.590573     7.185359   \n",
      "2        1       320         5   6.66      18934  7.590573     6.857294   \n",
      "3        1        49         8   7.38      20930  7.590573     7.515523   \n",
      "4        1       304         8   7.63      18571  7.590573     7.732777   \n",
      "\n",
      "   rating  \n",
      "0       9  \n",
      "1       7  \n",
      "2       5  \n",
      "3       8  \n",
      "4       8  \n"
     ]
    }
   ],
   "source": [
    "from category_encoders import TargetEncoder   \n",
    "\n",
    "# Handle missing values - example with 'score'\n",
    "final_df['score'].fillna(final_df['score'].mean(), inplace=True)\n",
    "\n",
    "# Define the target variable and categorical columns\n",
    "target_column = 'rating'\n",
    "categorical_columns = ['gender', 'Anime Title']\n",
    "\n",
    "# Create and fit the target encoder\n",
    "target_encoder = TargetEncoder(cols=categorical_columns)\n",
    "final_df[categorical_columns] = target_encoder.fit_transform(final_df[categorical_columns], final_df[target_column])\n",
    "\n",
    "# Drop any remaining rows with missing values if necessary\n",
    "final_df = final_df.dropna()\n",
    "\n",
    "# Display the first few rows after preprocessing and target encoding\n",
    "print(final_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (6021419, 7), y shape: (6021419,)\n"
     ]
    }
   ],
   "source": [
    "# Define features (X) and target (y)\n",
    "X = final_df.drop(columns=[target_column])\n",
    "y = final_df[target_column]\n",
    "\n",
    "# Display the shapes of X and y to confirm\n",
    "print(f'X shape: {X.shape}, y shape: {y.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to sample data\n",
    "def sample_data(X, y, sample_size):\n",
    "    if isinstance(sample_size, float):\n",
    "        if 0 < sample_size < 1.0:\n",
    "            return train_test_split(X, y, test_size=0.2, train_size=sample_size, random_state=42)\n",
    "        elif sample_size == 1.0:\n",
    "            return train_test_split(X, y, test_size=0.001, random_state=42)\n",
    "        else:\n",
    "            raise ValueError(\"sample_size as float must be in the range (0.0, 1.0) or equal to 1.0.\")\n",
    "    elif isinstance(sample_size, int):\n",
    "        if sample_size > len(X):\n",
    "            raise ValueError(f\"sample_size {sample_size} exceeds the number of available samples {len(X)}.\")\n",
    "        sampled_X = X.sample(n=sample_size, random_state=42)\n",
    "        sampled_y = y.loc[sampled_X.index]\n",
    "        return train_test_split(sampled_X, sampled_y, test_size=0.2, random_state=42)\n",
    "    else:\n",
    "        raise ValueError(\"sample_size must be a float or an integer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "import numpy as np\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "# Function to calculate and return metrics\n",
    "def calculate_metrics(X_train, X_test, y_train, y_test):\n",
    "    lr = LinearRegression()\n",
    "\n",
    "    # Define hyperparameters for RandomizedSearchCV\n",
    "    param_distributions = {\n",
    "        'fit_intercept': [True, False]\n",
    "    }\n",
    "\n",
    "    random_search = RandomizedSearchCV(lr, param_distributions, n_iter=2, cv=10, scoring='neg_mean_squared_error', random_state=42, n_jobs=-1)\n",
    "\n",
    "    start_time = time.time()\n",
    "    start_cpu = psutil.cpu_percent(interval=None)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    end_cpu = psutil.cpu_percent(interval=None)\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calculate time and CPU usage\n",
    "    execution_time = end_time - start_time\n",
    "    avg_cpu_usage = (start_cpu + end_cpu) / 2\n",
    "\n",
    "    y_pred = random_search.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    # Calculate the range of the target variable\n",
    "    target_range = y_train.max() - y_train.min()\n",
    "\n",
    "    # Calculate normalized RMSE (nRMSE)\n",
    "    nrmse = rmse / target_range\n",
    "    \n",
    "    memory_usage_MB = X_train.memory_usage(deep=True).sum() / (1024 ** 2)\n",
    "    normalized_time = execution_time / memory_usage_MB\n",
    "    \n",
    "    return {\n",
    "        'RMSE': rmse,\n",
    "        'MAPE': mape,\n",
    "        'R2': r2,\n",
    "        'MSE': mse,\n",
    "        'nRMSE': nrmse,  # Normalized RMSE\n",
    "        'Execution Time (Raw)': execution_time,  # Raw execution time\n",
    "        'Normalized Time (s/MB)': normalized_time,  # Normalized execution time\n",
    "        'Average CPU Usage': avg_cpu_usage\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for sample size 1.0:\n",
      "RMSE: 0.7505799728330512\n",
      "MAPE: 0.05866523534479733\n",
      "R2: 0.7972877254934723\n",
      "MSE: 0.5633702956180638\n",
      "nRMSE: 0.08339777475922791\n",
      "Execution Time (Raw): 16.839823246002197\n",
      "Normalized Time (s/MB): 0.045866243585003616\n",
      "Average CPU Usage: 53.400000000000006\n",
      "Sample Size: 1.0\n",
      "--------------------------------------------------\n",
      "Metrics for sample size 0.5:\n",
      "RMSE: 0.7313924397731141\n",
      "MAPE: 0.059349117034842004\n",
      "R2: 0.8073905648856209\n",
      "MSE: 0.5349349009572684\n",
      "nRMSE: 0.08126582664145712\n",
      "Execution Time (Raw): 7.707000255584717\n",
      "Normalized Time (s/MB): 0.04194078278156408\n",
      "Average CPU Usage: 52.6\n",
      "Sample Size: 0.5\n",
      "--------------------------------------------------\n",
      "Metrics for sample size 0.25:\n",
      "RMSE: 0.73139176284671\n",
      "MAPE: 0.05953974862172301\n",
      "R2: 0.8073909214174767\n",
      "MSE: 0.5349339107600182\n",
      "nRMSE: 0.08126575142741223\n",
      "Execution Time (Raw): 3.9185242652893066\n",
      "Normalized Time (s/MB): 0.042648507635081184\n",
      "Average CPU Usage: 55.6\n",
      "Sample Size: 0.25\n",
      "--------------------------------------------------\n",
      "Metrics for sample size 0.125:\n",
      "RMSE: 0.7313991127679468\n",
      "MAPE: 0.05979041877227558\n",
      "R2: 0.8073870502536433\n",
      "MSE: 0.5349446621577397\n",
      "nRMSE: 0.08126656808532742\n",
      "Execution Time (Raw): 2.481337308883667\n",
      "Normalized Time (s/MB): 0.05401285075636694\n",
      "Average CPU Usage: 71.9\n",
      "Sample Size: 0.125\n",
      "--------------------------------------------------\n",
      "Metrics for sample size 100:\n",
      "RMSE: 0.02063042015465816\n",
      "MAPE: 0.0021935672731574303\n",
      "R2: 0.9999023820560189\n",
      "MSE: 0.0004256142357577256\n",
      "nRMSE: 0.00257880251933227\n",
      "Execution Time (Raw): 0.05877566337585449\n",
      "Normalized Time (s/MB): 12.037255859375\n",
      "Average CPU Usage: 53.0\n",
      "Sample Size: 100\n",
      "--------------------------------------------------\n",
      "Metrics for sample size 1000:\n",
      "RMSE: 0.6053682283639082\n",
      "MAPE: 0.04637105961229345\n",
      "R2: 0.8654844902363086\n",
      "MSE: 0.3664706919124569\n",
      "nRMSE: 0.0672631364848787\n",
      "Execution Time (Raw): 0.04754996299743652\n",
      "Normalized Time (s/MB): 0.9738232421875\n",
      "Average CPU Usage: 33.15\n",
      "Sample Size: 1000\n",
      "--------------------------------------------------\n",
      "Metrics for sample size 10000:\n",
      "RMSE: 0.8186935635636279\n",
      "MAPE: 0.07279462974465821\n",
      "R2: 0.773957721642806\n",
      "MSE: 0.670259151020512\n",
      "nRMSE: 0.09096595150706976\n",
      "Execution Time (Raw): 0.08630681037902832\n",
      "Normalized Time (s/MB): 0.17675634765625\n",
      "Average CPU Usage: 60.3\n",
      "Sample Size: 10000\n",
      "--------------------------------------------------\n",
      "Metrics for sample size 100000:\n",
      "RMSE: 0.7433727867285487\n",
      "MAPE: 0.06192078296846935\n",
      "R2: 0.8018715965744816\n",
      "MSE: 0.5526031000485684\n",
      "nRMSE: 0.08259697630317207\n",
      "Execution Time (Raw): 0.65207839012146\n",
      "Normalized Time (s/MB): 0.133545654296875\n",
      "Average CPU Usage: 46.900000000000006\n",
      "Sample Size: 100000\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Define sample sizes\n",
    "sample_sizes = [1.0, 0.5, 0.25, 0.125, 100, 1000, 10000, 100000]\n",
    "\n",
    "# Initialize metrics storage\n",
    "metrics_list = []\n",
    "total_execution_time = 0\n",
    "total_cpu_usage = 0\n",
    "total_memory_usage_MB = 0\n",
    "\n",
    "# Loop through each sample size\n",
    "for size in sample_sizes:\n",
    "    try:\n",
    "        X_train_sample, X_test_sample, y_train_sample, y_test_sample = sample_data(X, y, size)\n",
    "        metrics = calculate_metrics(X_train_sample, X_test_sample, y_train_sample, y_test_sample)\n",
    "        metrics['Sample Size'] = size\n",
    "        metrics_list.append(metrics)\n",
    "\n",
    "        # Accumulate total       \n",
    "        total_execution_time += metrics['Execution Time (Raw)']\n",
    "        total_cpu_usage += metrics['Average CPU Usage']\n",
    "        total_memory_usage_MB += X_train_sample.memory_usage(deep=True).sum() / (1024 ** 2)\n",
    "\n",
    "        print(f\"Metrics for sample size {size}:\")\n",
    "        for key, value in metrics.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for sample size {size}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Execution Time for Entire Process (Raw): 0 minutes and 31.79 seconds\n",
      "Total Normalized Execution Time for Entire Process: 0.04579877 seconds per MB\n",
      "Total Average CPU Usage for Entire Process: 53.36%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE</th>\n",
       "      <th>nRMSE</th>\n",
       "      <th>Execution Time (Raw)</th>\n",
       "      <th>Normalized Time (s/MB)</th>\n",
       "      <th>Average CPU Usage</th>\n",
       "      <th>Sample Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.750580</td>\n",
       "      <td>0.058665</td>\n",
       "      <td>0.797288</td>\n",
       "      <td>0.563370</td>\n",
       "      <td>0.083398</td>\n",
       "      <td>16.839823</td>\n",
       "      <td>0.045866</td>\n",
       "      <td>53.40</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.731392</td>\n",
       "      <td>0.059349</td>\n",
       "      <td>0.807391</td>\n",
       "      <td>0.534935</td>\n",
       "      <td>0.081266</td>\n",
       "      <td>7.707000</td>\n",
       "      <td>0.041941</td>\n",
       "      <td>52.60</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.731392</td>\n",
       "      <td>0.059540</td>\n",
       "      <td>0.807391</td>\n",
       "      <td>0.534934</td>\n",
       "      <td>0.081266</td>\n",
       "      <td>3.918524</td>\n",
       "      <td>0.042649</td>\n",
       "      <td>55.60</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.731399</td>\n",
       "      <td>0.059790</td>\n",
       "      <td>0.807387</td>\n",
       "      <td>0.534945</td>\n",
       "      <td>0.081267</td>\n",
       "      <td>2.481337</td>\n",
       "      <td>0.054013</td>\n",
       "      <td>71.90</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.020630</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>0.999902</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.002579</td>\n",
       "      <td>0.058776</td>\n",
       "      <td>12.037256</td>\n",
       "      <td>53.00</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.605368</td>\n",
       "      <td>0.046371</td>\n",
       "      <td>0.865484</td>\n",
       "      <td>0.366471</td>\n",
       "      <td>0.067263</td>\n",
       "      <td>0.047550</td>\n",
       "      <td>0.973823</td>\n",
       "      <td>33.15</td>\n",
       "      <td>1000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.818694</td>\n",
       "      <td>0.072795</td>\n",
       "      <td>0.773958</td>\n",
       "      <td>0.670259</td>\n",
       "      <td>0.090966</td>\n",
       "      <td>0.086307</td>\n",
       "      <td>0.176756</td>\n",
       "      <td>60.30</td>\n",
       "      <td>10000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.743373</td>\n",
       "      <td>0.061921</td>\n",
       "      <td>0.801872</td>\n",
       "      <td>0.552603</td>\n",
       "      <td>0.082597</td>\n",
       "      <td>0.652078</td>\n",
       "      <td>0.133546</td>\n",
       "      <td>46.90</td>\n",
       "      <td>100000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       RMSE      MAPE        R2       MSE     nRMSE  Execution Time (Raw)  \\\n",
       "0  0.750580  0.058665  0.797288  0.563370  0.083398             16.839823   \n",
       "1  0.731392  0.059349  0.807391  0.534935  0.081266              7.707000   \n",
       "2  0.731392  0.059540  0.807391  0.534934  0.081266              3.918524   \n",
       "3  0.731399  0.059790  0.807387  0.534945  0.081267              2.481337   \n",
       "4  0.020630  0.002194  0.999902  0.000426  0.002579              0.058776   \n",
       "5  0.605368  0.046371  0.865484  0.366471  0.067263              0.047550   \n",
       "6  0.818694  0.072795  0.773958  0.670259  0.090966              0.086307   \n",
       "7  0.743373  0.061921  0.801872  0.552603  0.082597              0.652078   \n",
       "\n",
       "   Normalized Time (s/MB)  Average CPU Usage  Sample Size  \n",
       "0                0.045866              53.40        1.000  \n",
       "1                0.041941              52.60        0.500  \n",
       "2                0.042649              55.60        0.250  \n",
       "3                0.054013              71.90        0.125  \n",
       "4               12.037256              53.00      100.000  \n",
       "5                0.973823              33.15     1000.000  \n",
       "6                0.176756              60.30    10000.000  \n",
       "7                0.133546              46.90   100000.000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert metrics to DataFrame\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "\n",
    "# Calculate total metrics\n",
    "total_avg_cpu_usage = total_cpu_usage / len(sample_sizes)\n",
    "normalized_total_time = total_execution_time / total_memory_usage_MB\n",
    "\n",
    "# Convert total execution time to minutes and seconds\n",
    "total_minutes = int(total_execution_time // 60)\n",
    "total_seconds = total_execution_time % 60\n",
    "\n",
    "# Display total metrics\n",
    "print(f\"Total Execution Time for Entire Process (Raw): {total_minutes} minutes and {total_seconds:.2f} seconds\")\n",
    "print(f\"Total Normalized Execution Time for Entire Process: {normalized_total_time:.8f} seconds per MB\")\n",
    "print(f\"Total Average CPU Usage for Entire Process: {total_avg_cpu_usage:.2f}%\")\n",
    "\n",
    "# Display the metrics DataFrame\n",
    "metrics_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
