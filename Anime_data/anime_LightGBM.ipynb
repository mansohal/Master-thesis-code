{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  anime_id             Anime Title  rating  my_score gender  score  \\\n",
      "0        1        21               One Piece       9         9   Male   8.54   \n",
      "1        1        48             .hack//Sign       7         7   Male   7.09   \n",
      "2        1       320                  A Kite       5         5   Male   6.66   \n",
      "3        1        49        Aa! Megami-sama!       8         8   Male   7.38   \n",
      "4        1       304  Aa! Megami-sama! Movie       8         8   Male   7.63   \n",
      "\n",
      "   scored_by  popularity  \n",
      "0     423868          35  \n",
      "1      61485         650  \n",
      "2      18934        1946  \n",
      "3      20930        1807  \n",
      "4      18571        2007  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets with only the required columns\n",
    "df1 = pd.read_csv('C:/Users/Guest01/Documents/dataset_anime/archive/final_animedataset.csv', usecols=['user_id', 'anime_id', 'my_score', 'score', 'scored_by', 'gender', 'popularity'])\n",
    "df2 = pd.read_csv('C:/Users/Guest01/Documents/dataset_anime/archive/users-score-2023.csv', usecols=['user_id', 'anime_id', 'Anime Title', 'rating'])\n",
    "\n",
    "# Merge the datasets on user_id and anime_id\n",
    "final_df = pd.merge(df2, df1, on=['user_id', 'anime_id'])\n",
    "\n",
    "# Display the first few rows to check the data\n",
    "print(final_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guest01\\AppData\\Local\\Temp\\ipykernel_9036\\4112127917.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  final_df[col].fillna(final_df[col].median(), inplace=True)\n",
      "C:\\Users\\Guest01\\AppData\\Local\\Temp\\ipykernel_9036\\4112127917.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  final_df[col].fillna(final_df[col].median(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  anime_id  Anime Title  rating  my_score   gender  score  \\\n",
      "0        1        21        10462       9         9  4175028   8.54   \n",
      "1        1        48         5341       7         7  4175028   7.09   \n",
      "2        1       320         1892       5         5  4175028   6.66   \n",
      "3        1        49         2448       8         8  4175028   7.38   \n",
      "4        1       304         2395       8         8  4175028   7.63   \n",
      "\n",
      "   scored_by  popularity  \n",
      "0     423868          35  \n",
      "1      61485         650  \n",
      "2      18934        1946  \n",
      "3      20930        1807  \n",
      "4      18571        2007  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guest01\\AppData\\Local\\Temp\\ipykernel_9036\\4112127917.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  final_df[col].fillna(final_df[col].median(), inplace=True)\n",
      "C:\\Users\\Guest01\\AppData\\Local\\Temp\\ipykernel_9036\\4112127917.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  final_df[col].fillna(final_df[col].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Frequency encoding for categorical columns\n",
    "categorical_columns = ['gender', 'Anime Title']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    freq = final_df[col].value_counts()\n",
    "    final_df[col] = final_df[col].map(freq)\n",
    "\n",
    "# Handle missing values by filling with median for numerical columns\n",
    "numerical_columns = ['my_score', 'score', 'scored_by', 'popularity']\n",
    "for col in numerical_columns:\n",
    "    final_df[col].fillna(final_df[col].median(), inplace=True)\n",
    "\n",
    "# Display the first few rows after preprocessing\n",
    "print(final_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (6021419, 8), y shape: (6021419,)\n"
     ]
    }
   ],
   "source": [
    "# Define features (X) and target (y)\n",
    "X = final_df.drop(columns=['rating'])  # All columns except 'rating' are features\n",
    "y = final_df['rating']  # 'rating' is the target variable\n",
    "\n",
    "# Display the shapes of X and y to confirm\n",
    "print(f'X shape: {X.shape}, y shape: {y.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to sample data\n",
    "def sample_data(X, y, sample_size):\n",
    "    if isinstance(sample_size, float):\n",
    "        if 0 < sample_size < 1.0:\n",
    "            return train_test_split(X, y, test_size=0.2, train_size=sample_size, random_state=42)\n",
    "        elif sample_size == 1.0:\n",
    "            return train_test_split(X, y, test_size=0.001, random_state=42)\n",
    "        else:\n",
    "            raise ValueError(\"sample_size as float must be in the range (0.0, 1.0) or equal to 1.0.\")\n",
    "    elif isinstance(sample_size, int):\n",
    "        if sample_size > len(X):\n",
    "            raise ValueError(f\"sample_size {sample_size} exceeds the number of available samples {len(X)}.\")\n",
    "        sampled_X = X.sample(n=sample_size, random_state=42)\n",
    "        sampled_y = y.loc[sampled_X.index]\n",
    "        return train_test_split(sampled_X, sampled_y, test_size=0.2, random_state=42)\n",
    "    else:\n",
    "        raise ValueError(\"sample_size must be a float or an integer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "import numpy as np\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "# Function to calculate and return metrics\n",
    "def calculate_metrics(X_train, X_test, y_train, y_test):\n",
    "    lgbm = LGBMRegressor()\n",
    "\n",
    "    # Define enhanced hyperparameters for RandomizedSearchCV\n",
    "    param_distributions = {\n",
    "        'n_estimators': [30, 50],  # Number of boosting stages\n",
    "        'learning_rate': [0.05, 0.1],  # Step size shrinkage\n",
    "        'max_depth': [3, 5, 7, 10, 15, 20],  # Maximum depth of individual trees\n",
    "        'min_child_samples': [20, 30, 40],  # Minimum number of samples in a leaf\n",
    "        'subsample': [0.8, 0.9, 1.0],  # Fraction of samples used for training\n",
    "        'colsample_bytree': [0.8, 0.9, 1.0],  # Fraction of features used per tree\n",
    "        'force_col_wise': [True],  # Force data to be stored column-wise\n",
    "        'reg_alpha': [0, 0.01, 0.1, 1, 10],  # L1 regularization term\n",
    "        'reg_lambda': [0, 0.01, 0.1, 1, 10]  # L2 regularization term\n",
    "    }\n",
    "\n",
    "    random_search = RandomizedSearchCV(\n",
    "        lgbm,\n",
    "        param_distributions,\n",
    "        n_iter=10,\n",
    "        cv=5,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "    start_cpu = psutil.cpu_percent(interval=None)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    end_cpu = psutil.cpu_percent(interval=None)\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calculate time and CPU usage\n",
    "    execution_time = end_time - start_time\n",
    "    avg_cpu_usage = (start_cpu + end_cpu) / 2\n",
    "\n",
    "    y_pred = random_search.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    # Calculate the range of the target variable\n",
    "    target_range = y_train.max() - y_train.min()\n",
    "\n",
    "    # Calculate normalized RMSE (nRMSE)\n",
    "    nrmse = rmse / target_range\n",
    "    \n",
    "    memory_usage_MB = X_train.memory_usage(deep=True).sum() / (1024 ** 2)\n",
    "    normalized_time = execution_time / memory_usage_MB\n",
    "    \n",
    "    return {\n",
    "        'RMSE': rmse,\n",
    "        'MAPE': mape,\n",
    "        'R2': r2,\n",
    "        'MSE': mse,\n",
    "        'nRMSE': nrmse,  # Normalized RMSE\n",
    "        'Execution Time (Raw)': execution_time,  # Raw execution time\n",
    "        'Normalized Time (s/MB)': normalized_time,  # Normalized execution time\n",
    "        'Average CPU Usage': avg_cpu_usage\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1521\n",
      "[LightGBM] [Info] Number of data points in the train set: 6015397, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 7.619075\n",
      "Metrics for sample size 1.0:\n",
      "RMSE: 0.2521050413009392\n",
      "MAPE: 0.010311401305564119\n",
      "R2: 0.9771308953093655\n",
      "MSE: 0.06355695184934826\n",
      "nRMSE: 0.028011671255659912\n",
      "Execution Time (Raw): 233.95305609703064\n",
      "Normalized Time (s/MB): 0.566411216061236\n",
      "Average CPU Usage: 57.6\n",
      "Sample Size: 1.0\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1522\n",
      "[LightGBM] [Info] Number of data points in the train set: 3010709, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 7.618789\n",
      "Metrics for sample size 0.5:\n",
      "RMSE: 0.26910562361830304\n",
      "MAPE: 0.01141358321268742\n",
      "R2: 0.9739251288579146\n",
      "MSE: 0.07241783666299577\n",
      "nRMSE: 0.029900624846478114\n",
      "Execution Time (Raw): 117.68722796440125\n",
      "Normalized Time (s/MB): 0.569282678146207\n",
      "Average CPU Usage: 58.75\n",
      "Sample Size: 0.5\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1521\n",
      "[LightGBM] [Info] Number of data points in the train set: 1505354, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 7.619702\n",
      "Metrics for sample size 0.25:\n",
      "RMSE: 0.26935368776361684\n",
      "MAPE: 0.011470433850622087\n",
      "R2: 0.9738770345685411\n",
      "MSE: 0.07255140911186\n",
      "nRMSE: 0.02992818752929076\n",
      "Execution Time (Raw): 57.90630054473877\n",
      "Normalized Time (s/MB): 0.5602148232243047\n",
      "Average CPU Usage: 65.95\n",
      "Sample Size: 0.25\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1522\n",
      "[LightGBM] [Info] Number of data points in the train set: 752677, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 7.618775\n",
      "Metrics for sample size 0.125:\n",
      "RMSE: 0.26964244821621663\n",
      "MAPE: 0.011547776591103096\n",
      "R2: 0.973820994328158\n",
      "MSE: 0.07270704988003507\n",
      "nRMSE: 0.02996027202402407\n",
      "Execution Time (Raw): 32.37647271156311\n",
      "Normalized Time (s/MB): 0.6264527267709492\n",
      "Average CPU Usage: 65.1\n",
      "Sample Size: 0.125\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 80, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 7.737500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Metrics for sample size 100:\n",
      "RMSE: 1.2233957564406492\n",
      "MAPE: 0.17953741822882052\n",
      "R2: 0.6567208309915165\n",
      "MSE: 1.4966971768769886\n",
      "nRMSE: 0.15292446955508116\n",
      "Execution Time (Raw): 0.4101448059082031\n",
      "Normalized Time (s/MB): 74.66458333333334\n",
      "Average CPU Usage: 71.8\n",
      "Sample Size: 100\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1437\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 7.503750\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Metrics for sample size 1000:\n",
      "RMSE: 0.27735131811010727\n",
      "MAPE: 0.02275648536468035\n",
      "R2: 0.971764623571493\n",
      "MSE: 0.07692375365741393\n",
      "nRMSE: 0.030816813123345253\n",
      "Execution Time (Raw): 0.6236040592193604\n",
      "Normalized Time (s/MB): 11.35236545138889\n",
      "Average CPU Usage: 68.3\n",
      "Sample Size: 1000\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1518\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 7.639250\n",
      "Metrics for sample size 10000:\n",
      "RMSE: 0.31674914742555516\n",
      "MAPE: 0.01364701657986856\n",
      "R2: 0.9661640921795359\n",
      "MSE: 0.10033002239481607\n",
      "nRMSE: 0.03519434971395057\n",
      "Execution Time (Raw): 1.3010339736938477\n",
      "Normalized Time (s/MB): 2.3684600694444446\n",
      "Average CPU Usage: 64.75\n",
      "Sample Size: 10000\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1520\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 7.625425\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Metrics for sample size 100000:\n",
      "RMSE: 0.2632874300308951\n",
      "MAPE: 0.011602636843594718\n",
      "R2: 0.9751461499585268\n",
      "MSE: 0.0693202708122735\n",
      "nRMSE: 0.029254158892321677\n",
      "Execution Time (Raw): 5.543799161911011\n",
      "Normalized Time (s/MB): 1.0092178385416666\n",
      "Average CPU Usage: 65.75\n",
      "Sample Size: 100000\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Define sample sizes\n",
    "sample_sizes = [1.0, 0.5, 0.25, 0.125, 100, 1000, 10000, 100000]\n",
    "\n",
    "# Initialize metrics storage\n",
    "metrics_list = []\n",
    "total_execution_time = 0\n",
    "total_cpu_usage = 0\n",
    "total_memory_usage_MB = 0\n",
    "\n",
    "# Loop through each sample size\n",
    "for size in sample_sizes:\n",
    "    try:\n",
    "        X_train_sample, X_test_sample, y_train_sample, y_test_sample = sample_data(X, y, size)\n",
    "        metrics = calculate_metrics(X_train_sample, X_test_sample, y_train_sample, y_test_sample)\n",
    "        metrics['Sample Size'] = size\n",
    "        metrics_list.append(metrics)\n",
    "\n",
    "        # Accumulate total       \n",
    "        total_execution_time += metrics['Execution Time (Raw)']\n",
    "        total_cpu_usage += metrics['Average CPU Usage']\n",
    "        total_memory_usage_MB += X_train_sample.memory_usage(deep=True).sum() / (1024 ** 2)\n",
    "\n",
    "        print(f\"Metrics for sample size {size}:\")\n",
    "        for key, value in metrics.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for sample size {size}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Execution Time for Entire Process (Raw): 7 minutes and 29.80 seconds\n",
      "Total Normalized Execution Time for Entire Process: 0.57598711 seconds per MB\n",
      "Total Average CPU Usage for Entire Process: 64.75%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE</th>\n",
       "      <th>nRMSE</th>\n",
       "      <th>Execution Time (Raw)</th>\n",
       "      <th>Normalized Time (s/MB)</th>\n",
       "      <th>Average CPU Usage</th>\n",
       "      <th>Sample Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.252105</td>\n",
       "      <td>0.010311</td>\n",
       "      <td>0.977131</td>\n",
       "      <td>0.063557</td>\n",
       "      <td>0.028012</td>\n",
       "      <td>233.953056</td>\n",
       "      <td>0.566411</td>\n",
       "      <td>57.60</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.269106</td>\n",
       "      <td>0.011414</td>\n",
       "      <td>0.973925</td>\n",
       "      <td>0.072418</td>\n",
       "      <td>0.029901</td>\n",
       "      <td>117.687228</td>\n",
       "      <td>0.569283</td>\n",
       "      <td>58.75</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.269354</td>\n",
       "      <td>0.011470</td>\n",
       "      <td>0.973877</td>\n",
       "      <td>0.072551</td>\n",
       "      <td>0.029928</td>\n",
       "      <td>57.906301</td>\n",
       "      <td>0.560215</td>\n",
       "      <td>65.95</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.269642</td>\n",
       "      <td>0.011548</td>\n",
       "      <td>0.973821</td>\n",
       "      <td>0.072707</td>\n",
       "      <td>0.029960</td>\n",
       "      <td>32.376473</td>\n",
       "      <td>0.626453</td>\n",
       "      <td>65.10</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.223396</td>\n",
       "      <td>0.179537</td>\n",
       "      <td>0.656721</td>\n",
       "      <td>1.496697</td>\n",
       "      <td>0.152924</td>\n",
       "      <td>0.410145</td>\n",
       "      <td>74.664583</td>\n",
       "      <td>71.80</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.277351</td>\n",
       "      <td>0.022756</td>\n",
       "      <td>0.971765</td>\n",
       "      <td>0.076924</td>\n",
       "      <td>0.030817</td>\n",
       "      <td>0.623604</td>\n",
       "      <td>11.352365</td>\n",
       "      <td>68.30</td>\n",
       "      <td>1000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.316749</td>\n",
       "      <td>0.013647</td>\n",
       "      <td>0.966164</td>\n",
       "      <td>0.100330</td>\n",
       "      <td>0.035194</td>\n",
       "      <td>1.301034</td>\n",
       "      <td>2.368460</td>\n",
       "      <td>64.75</td>\n",
       "      <td>10000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.263287</td>\n",
       "      <td>0.011603</td>\n",
       "      <td>0.975146</td>\n",
       "      <td>0.069320</td>\n",
       "      <td>0.029254</td>\n",
       "      <td>5.543799</td>\n",
       "      <td>1.009218</td>\n",
       "      <td>65.75</td>\n",
       "      <td>100000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       RMSE      MAPE        R2       MSE     nRMSE  Execution Time (Raw)  \\\n",
       "0  0.252105  0.010311  0.977131  0.063557  0.028012            233.953056   \n",
       "1  0.269106  0.011414  0.973925  0.072418  0.029901            117.687228   \n",
       "2  0.269354  0.011470  0.973877  0.072551  0.029928             57.906301   \n",
       "3  0.269642  0.011548  0.973821  0.072707  0.029960             32.376473   \n",
       "4  1.223396  0.179537  0.656721  1.496697  0.152924              0.410145   \n",
       "5  0.277351  0.022756  0.971765  0.076924  0.030817              0.623604   \n",
       "6  0.316749  0.013647  0.966164  0.100330  0.035194              1.301034   \n",
       "7  0.263287  0.011603  0.975146  0.069320  0.029254              5.543799   \n",
       "\n",
       "   Normalized Time (s/MB)  Average CPU Usage  Sample Size  \n",
       "0                0.566411              57.60        1.000  \n",
       "1                0.569283              58.75        0.500  \n",
       "2                0.560215              65.95        0.250  \n",
       "3                0.626453              65.10        0.125  \n",
       "4               74.664583              71.80      100.000  \n",
       "5               11.352365              68.30     1000.000  \n",
       "6                2.368460              64.75    10000.000  \n",
       "7                1.009218              65.75   100000.000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert metrics to DataFrame\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "\n",
    "# Calculate total metrics\n",
    "total_avg_cpu_usage = total_cpu_usage / len(sample_sizes)\n",
    "normalized_total_time = total_execution_time / total_memory_usage_MB\n",
    "\n",
    "# Convert total execution time to minutes and seconds\n",
    "total_minutes = int(total_execution_time // 60)\n",
    "total_seconds = total_execution_time % 60\n",
    "\n",
    "# Display total metrics\n",
    "print(f\"Total Execution Time for Entire Process (Raw): {total_minutes} minutes and {total_seconds:.2f} seconds\")\n",
    "print(f\"Total Normalized Execution Time for Entire Process: {normalized_total_time:.8f} seconds per MB\")\n",
    "print(f\"Total Average CPU Usage for Entire Process: {total_avg_cpu_usage:.2f}%\")\n",
    "\n",
    "# Display the metrics DataFrame\n",
    "metrics_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "another iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "import numpy as np\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "# Function to calculate and return metrics\n",
    "def calculate_metrics(X_train, X_test, y_train, y_test):\n",
    "    lgbm = LGBMRegressor()\n",
    "\n",
    "    # Define enhanced hyperparameters for RandomizedSearchCV\n",
    "    param_distributions = {\n",
    "        'n_estimators': [30, 50],  # Number of boosting stages\n",
    "        'learning_rate': [0.05, 0.1],  # Step size shrinkage\n",
    "        'max_depth': [3, 5, 7, 10, 15, 20, 30],  # Maximum depth of individual trees\n",
    "        'min_child_samples': [20, 30, 40, 50],  # Minimum number of samples in a leaf\n",
    "        'subsample': [0.8, 0.9, 1.0],  # Fraction of samples used for training\n",
    "        'colsample_bytree': [0.8, 0.9, 1.0],  # Fraction of features used per tree\n",
    "        'force_col_wise': [True],  # Force data to be stored column-wise\n",
    "        'reg_alpha': [0, 0.01, 0.1, 1, 10],  # L1 regularization term\n",
    "        'reg_lambda': [0, 0.01, 0.1, 1, 10]  # L2 regularization term\n",
    "    }\n",
    "\n",
    "    random_search = RandomizedSearchCV(\n",
    "        lgbm,\n",
    "        param_distributions,\n",
    "        n_iter=10,\n",
    "        cv=5,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "    start_cpu = psutil.cpu_percent(interval=None)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    end_cpu = psutil.cpu_percent(interval=None)\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calculate time and CPU usage\n",
    "    execution_time = end_time - start_time\n",
    "    avg_cpu_usage = (start_cpu + end_cpu) / 2\n",
    "\n",
    "    y_pred = random_search.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    # Calculate the range of the target variable\n",
    "    target_range = y_train.max() - y_train.min()\n",
    "\n",
    "    # Calculate normalized RMSE (nRMSE)\n",
    "    nrmse = rmse / target_range\n",
    "    \n",
    "    memory_usage_MB = X_train.memory_usage(deep=True).sum() / (1024 ** 2)\n",
    "    normalized_time = execution_time / memory_usage_MB\n",
    "    \n",
    "    return {\n",
    "        'RMSE': rmse,\n",
    "        'MAPE': mape,\n",
    "        'R2': r2,\n",
    "        'MSE': mse,\n",
    "        'nRMSE': nrmse,  # Normalized RMSE\n",
    "        'Execution Time (Raw)': execution_time,  # Raw execution time\n",
    "        'Normalized Time (s/MB)': normalized_time,  # Normalized execution time\n",
    "        'Average CPU Usage': avg_cpu_usage\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1521\n",
      "[LightGBM] [Info] Number of data points in the train set: 6015397, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 7.619075\n",
      "Metrics for sample size 1.0:\n",
      "RMSE: 0.24837468284654893\n",
      "MAPE: 0.008203456422378647\n",
      "R2: 0.97780266925412\n",
      "MSE: 0.06168998307912377\n",
      "nRMSE: 0.02759718698294988\n",
      "Execution Time (Raw): 242.77227187156677\n",
      "Normalized Time (s/MB): 0.5877629471088941\n",
      "Average CPU Usage: 50.599999999999994\n",
      "Sample Size: 1.0\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1522\n",
      "[LightGBM] [Info] Number of data points in the train set: 3010709, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 7.618789\n",
      "Metrics for sample size 0.5:\n",
      "RMSE: 0.26749505980621047\n",
      "MAPE: 0.009344220290541149\n",
      "R2: 0.9742363046344593\n",
      "MSE: 0.0715536070207281\n",
      "nRMSE: 0.029721673311801162\n",
      "Execution Time (Raw): 133.92271041870117\n",
      "Normalized Time (s/MB): 0.6478177842273476\n",
      "Average CPU Usage: 65.35\n",
      "Sample Size: 0.5\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1521\n",
      "[LightGBM] [Info] Number of data points in the train set: 1505354, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 7.619702\n",
      "Metrics for sample size 0.25:\n",
      "RMSE: 0.2679368927100595\n",
      "MAPE: 0.009336109177812097\n",
      "R2: 0.9741511243739951\n",
      "MSE: 0.07179017847512194\n",
      "nRMSE: 0.02977076585667328\n",
      "Execution Time (Raw): 79.45962738990784\n",
      "Normalized Time (s/MB): 0.7687326023756981\n",
      "Average CPU Usage: 70.3\n",
      "Sample Size: 0.25\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1522\n",
      "[LightGBM] [Info] Number of data points in the train set: 752677, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 7.618775\n",
      "Metrics for sample size 0.125:\n",
      "RMSE: 0.2684513397262069\n",
      "MAPE: 0.009383070033236882\n",
      "R2: 0.9740517678205407\n",
      "MSE: 0.07206612180079534\n",
      "nRMSE: 0.02982792663624521\n",
      "Execution Time (Raw): 42.70007848739624\n",
      "Normalized Time (s/MB): 0.8262042885298445\n",
      "Average CPU Usage: 77.8\n",
      "Sample Size: 0.125\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 80, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 7.737500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Metrics for sample size 100:\n",
      "RMSE: 1.2774625803890125\n",
      "MAPE: 0.18806575859155347\n",
      "R2: 0.6257085678224418\n",
      "MSE: 1.631910644294154\n",
      "nRMSE: 0.15968282254862656\n",
      "Execution Time (Raw): 0.3353087902069092\n",
      "Normalized Time (s/MB): 61.041102430555554\n",
      "Average CPU Usage: 75.3\n",
      "Sample Size: 100\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1437\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 7.503750\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Metrics for sample size 1000:\n",
      "RMSE: 0.2915261426970115\n",
      "MAPE: 0.02012192659850574\n",
      "R2: 0.9688047747186792\n",
      "MSE: 0.08498749187579832\n",
      "nRMSE: 0.03239179363300128\n",
      "Execution Time (Raw): 0.8263757228851318\n",
      "Normalized Time (s/MB): 15.0437109375\n",
      "Average CPU Usage: 72.95\n",
      "Sample Size: 1000\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1518\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 7.639250\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Metrics for sample size 10000:\n",
      "RMSE: 0.3168823574910948\n",
      "MAPE: 0.010935809467232493\n",
      "R2: 0.9661356265542128\n",
      "MSE: 0.10041442848911399\n",
      "nRMSE: 0.03520915083234386\n",
      "Execution Time (Raw): 1.8807573318481445\n",
      "Normalized Time (s/MB): 3.4238142361111112\n",
      "Average CPU Usage: 76.1\n",
      "Sample Size: 10000\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1520\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 7.625425\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Metrics for sample size 100000:\n",
      "RMSE: 0.2640412601608271\n",
      "MAPE: 0.01176496680018752\n",
      "R2: 0.9750036258558922\n",
      "MSE: 0.06971778706731757\n",
      "nRMSE: 0.029337917795647452\n",
      "Execution Time (Raw): 8.436198472976685\n",
      "Normalized Time (s/MB): 1.535763064236111\n",
      "Average CPU Usage: 68.7\n",
      "Sample Size: 100000\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Define sample sizes\n",
    "sample_sizes = [1.0, 0.5, 0.25, 0.125, 100, 1000, 10000, 100000]\n",
    "\n",
    "# Initialize metrics storage\n",
    "metrics_list = []\n",
    "total_execution_time = 0\n",
    "total_cpu_usage = 0\n",
    "total_memory_usage_MB = 0\n",
    "\n",
    "# Loop through each sample size\n",
    "for size in sample_sizes:\n",
    "    try:\n",
    "        X_train_sample, X_test_sample, y_train_sample, y_test_sample = sample_data(X, y, size)\n",
    "        metrics = calculate_metrics(X_train_sample, X_test_sample, y_train_sample, y_test_sample)\n",
    "        metrics['Sample Size'] = size\n",
    "        metrics_list.append(metrics)\n",
    "\n",
    "        # Accumulate total       \n",
    "        total_execution_time += metrics['Execution Time (Raw)']\n",
    "        total_cpu_usage += metrics['Average CPU Usage']\n",
    "        total_memory_usage_MB += X_train_sample.memory_usage(deep=True).sum() / (1024 ** 2)\n",
    "\n",
    "        print(f\"Metrics for sample size {size}:\")\n",
    "        for key, value in metrics.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for sample size {size}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Execution Time for Entire Process (Raw): 8 minutes and 30.33 seconds\n",
      "Total Normalized Execution Time for Entire Process: 0.65350010 seconds per MB\n",
      "Total Average CPU Usage for Entire Process: 69.64%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE</th>\n",
       "      <th>nRMSE</th>\n",
       "      <th>Execution Time (Raw)</th>\n",
       "      <th>Normalized Time (s/MB)</th>\n",
       "      <th>Average CPU Usage</th>\n",
       "      <th>Sample Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.248375</td>\n",
       "      <td>0.008203</td>\n",
       "      <td>0.977803</td>\n",
       "      <td>0.061690</td>\n",
       "      <td>0.027597</td>\n",
       "      <td>242.772272</td>\n",
       "      <td>0.587763</td>\n",
       "      <td>50.60</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.267495</td>\n",
       "      <td>0.009344</td>\n",
       "      <td>0.974236</td>\n",
       "      <td>0.071554</td>\n",
       "      <td>0.029722</td>\n",
       "      <td>133.922710</td>\n",
       "      <td>0.647818</td>\n",
       "      <td>65.35</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.267937</td>\n",
       "      <td>0.009336</td>\n",
       "      <td>0.974151</td>\n",
       "      <td>0.071790</td>\n",
       "      <td>0.029771</td>\n",
       "      <td>79.459627</td>\n",
       "      <td>0.768733</td>\n",
       "      <td>70.30</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.268451</td>\n",
       "      <td>0.009383</td>\n",
       "      <td>0.974052</td>\n",
       "      <td>0.072066</td>\n",
       "      <td>0.029828</td>\n",
       "      <td>42.700078</td>\n",
       "      <td>0.826204</td>\n",
       "      <td>77.80</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.277463</td>\n",
       "      <td>0.188066</td>\n",
       "      <td>0.625709</td>\n",
       "      <td>1.631911</td>\n",
       "      <td>0.159683</td>\n",
       "      <td>0.335309</td>\n",
       "      <td>61.041102</td>\n",
       "      <td>75.30</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.291526</td>\n",
       "      <td>0.020122</td>\n",
       "      <td>0.968805</td>\n",
       "      <td>0.084987</td>\n",
       "      <td>0.032392</td>\n",
       "      <td>0.826376</td>\n",
       "      <td>15.043711</td>\n",
       "      <td>72.95</td>\n",
       "      <td>1000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.316882</td>\n",
       "      <td>0.010936</td>\n",
       "      <td>0.966136</td>\n",
       "      <td>0.100414</td>\n",
       "      <td>0.035209</td>\n",
       "      <td>1.880757</td>\n",
       "      <td>3.423814</td>\n",
       "      <td>76.10</td>\n",
       "      <td>10000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.264041</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.975004</td>\n",
       "      <td>0.069718</td>\n",
       "      <td>0.029338</td>\n",
       "      <td>8.436198</td>\n",
       "      <td>1.535763</td>\n",
       "      <td>68.70</td>\n",
       "      <td>100000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       RMSE      MAPE        R2       MSE     nRMSE  Execution Time (Raw)  \\\n",
       "0  0.248375  0.008203  0.977803  0.061690  0.027597            242.772272   \n",
       "1  0.267495  0.009344  0.974236  0.071554  0.029722            133.922710   \n",
       "2  0.267937  0.009336  0.974151  0.071790  0.029771             79.459627   \n",
       "3  0.268451  0.009383  0.974052  0.072066  0.029828             42.700078   \n",
       "4  1.277463  0.188066  0.625709  1.631911  0.159683              0.335309   \n",
       "5  0.291526  0.020122  0.968805  0.084987  0.032392              0.826376   \n",
       "6  0.316882  0.010936  0.966136  0.100414  0.035209              1.880757   \n",
       "7  0.264041  0.011765  0.975004  0.069718  0.029338              8.436198   \n",
       "\n",
       "   Normalized Time (s/MB)  Average CPU Usage  Sample Size  \n",
       "0                0.587763              50.60        1.000  \n",
       "1                0.647818              65.35        0.500  \n",
       "2                0.768733              70.30        0.250  \n",
       "3                0.826204              77.80        0.125  \n",
       "4               61.041102              75.30      100.000  \n",
       "5               15.043711              72.95     1000.000  \n",
       "6                3.423814              76.10    10000.000  \n",
       "7                1.535763              68.70   100000.000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert metrics to DataFrame\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "\n",
    "# Calculate total metrics\n",
    "total_avg_cpu_usage = total_cpu_usage / len(sample_sizes)\n",
    "normalized_total_time = total_execution_time / total_memory_usage_MB\n",
    "\n",
    "# Convert total execution time to minutes and seconds\n",
    "total_minutes = int(total_execution_time // 60)\n",
    "total_seconds = total_execution_time % 60\n",
    "\n",
    "# Display total metrics\n",
    "print(f\"Total Execution Time for Entire Process (Raw): {total_minutes} minutes and {total_seconds:.2f} seconds\")\n",
    "print(f\"Total Normalized Execution Time for Entire Process: {normalized_total_time:.8f} seconds per MB\")\n",
    "print(f\"Total Average CPU Usage for Entire Process: {total_avg_cpu_usage:.2f}%\")\n",
    "\n",
    "# Display the metrics DataFrame\n",
    "metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
