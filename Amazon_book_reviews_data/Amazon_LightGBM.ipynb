{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('E:/Master_thesis_REV/Datasets/Dataset_amazon_book_reviews/archive/books_data.csv')\n",
    "ratings = pd.read_csv('E:/Master_thesis_REV/Datasets/Dataset_amazon_book_reviews/archive/Books_rating.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>description</th>\n",
       "      <th>authors</th>\n",
       "      <th>image</th>\n",
       "      <th>previewLink</th>\n",
       "      <th>publisher</th>\n",
       "      <th>publishedDate</th>\n",
       "      <th>infoLink</th>\n",
       "      <th>categories</th>\n",
       "      <th>ratingsCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Its Only Art If Its Well Hung!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Julie Strain']</td>\n",
       "      <td>http://books.google.com/books/content?id=DykPA...</td>\n",
       "      <td>http://books.google.nl/books?id=DykPAAAACAAJ&amp;d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1996</td>\n",
       "      <td>http://books.google.nl/books?id=DykPAAAACAAJ&amp;d...</td>\n",
       "      <td>['Comics &amp; Graphic Novels']</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>Philip Nel takes a fascinating look into the k...</td>\n",
       "      <td>['Philip Nel']</td>\n",
       "      <td>http://books.google.com/books/content?id=IjvHQ...</td>\n",
       "      <td>http://books.google.nl/books?id=IjvHQsCn_pgC&amp;p...</td>\n",
       "      <td>A&amp;C Black</td>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>http://books.google.nl/books?id=IjvHQsCn_pgC&amp;d...</td>\n",
       "      <td>['Biography &amp; Autobiography']</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wonderful Worship in Smaller Churches</td>\n",
       "      <td>This resource includes twelve principles in un...</td>\n",
       "      <td>['David R. Ray']</td>\n",
       "      <td>http://books.google.com/books/content?id=2tsDA...</td>\n",
       "      <td>http://books.google.nl/books?id=2tsDAAAACAAJ&amp;d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>http://books.google.nl/books?id=2tsDAAAACAAJ&amp;d...</td>\n",
       "      <td>['Religion']</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Whispers of the Wicked Saints</td>\n",
       "      <td>Julia Thomas finds her life spinning out of co...</td>\n",
       "      <td>['Veronica Haddon']</td>\n",
       "      <td>http://books.google.com/books/content?id=aRSIg...</td>\n",
       "      <td>http://books.google.nl/books?id=aRSIgJlq6JwC&amp;d...</td>\n",
       "      <td>iUniverse</td>\n",
       "      <td>2005-02</td>\n",
       "      <td>http://books.google.nl/books?id=aRSIgJlq6JwC&amp;d...</td>\n",
       "      <td>['Fiction']</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nation Dance: Religion, Identity and Cultural ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Edward Long']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://books.google.nl/books?id=399SPgAACAAJ&amp;d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2003-03-01</td>\n",
       "      <td>http://books.google.nl/books?id=399SPgAACAAJ&amp;d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                     Its Only Art If Its Well Hung!   \n",
       "1                           Dr. Seuss: American Icon   \n",
       "2              Wonderful Worship in Smaller Churches   \n",
       "3                      Whispers of the Wicked Saints   \n",
       "4  Nation Dance: Religion, Identity and Cultural ...   \n",
       "\n",
       "                                         description              authors  \\\n",
       "0                                                NaN     ['Julie Strain']   \n",
       "1  Philip Nel takes a fascinating look into the k...       ['Philip Nel']   \n",
       "2  This resource includes twelve principles in un...     ['David R. Ray']   \n",
       "3  Julia Thomas finds her life spinning out of co...  ['Veronica Haddon']   \n",
       "4                                                NaN      ['Edward Long']   \n",
       "\n",
       "                                               image  \\\n",
       "0  http://books.google.com/books/content?id=DykPA...   \n",
       "1  http://books.google.com/books/content?id=IjvHQ...   \n",
       "2  http://books.google.com/books/content?id=2tsDA...   \n",
       "3  http://books.google.com/books/content?id=aRSIg...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                         previewLink  publisher publishedDate  \\\n",
       "0  http://books.google.nl/books?id=DykPAAAACAAJ&d...        NaN          1996   \n",
       "1  http://books.google.nl/books?id=IjvHQsCn_pgC&p...  A&C Black    2005-01-01   \n",
       "2  http://books.google.nl/books?id=2tsDAAAACAAJ&d...        NaN          2000   \n",
       "3  http://books.google.nl/books?id=aRSIgJlq6JwC&d...  iUniverse       2005-02   \n",
       "4  http://books.google.nl/books?id=399SPgAACAAJ&d...        NaN    2003-03-01   \n",
       "\n",
       "                                            infoLink  \\\n",
       "0  http://books.google.nl/books?id=DykPAAAACAAJ&d...   \n",
       "1  http://books.google.nl/books?id=IjvHQsCn_pgC&d...   \n",
       "2  http://books.google.nl/books?id=2tsDAAAACAAJ&d...   \n",
       "3  http://books.google.nl/books?id=aRSIgJlq6JwC&d...   \n",
       "4  http://books.google.nl/books?id=399SPgAACAAJ&d...   \n",
       "\n",
       "                      categories  ratingsCount  \n",
       "0    ['Comics & Graphic Novels']           NaN  \n",
       "1  ['Biography & Autobiography']           NaN  \n",
       "2                   ['Religion']           NaN  \n",
       "3                    ['Fiction']           NaN  \n",
       "4                            NaN           NaN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>User_id</th>\n",
       "      <th>profileName</th>\n",
       "      <th>review/helpfulness</th>\n",
       "      <th>review/score</th>\n",
       "      <th>review/time</th>\n",
       "      <th>review/summary</th>\n",
       "      <th>review/text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1882931173</td>\n",
       "      <td>Its Only Art If Its Well Hung!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AVCGYZL8FQQTD</td>\n",
       "      <td>Jim of Oz \"jim-of-oz\"</td>\n",
       "      <td>7/7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>940636800</td>\n",
       "      <td>Nice collection of Julie Strain images</td>\n",
       "      <td>This is only for Julie Strain fans. It's a col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A30TK6U7DNS82R</td>\n",
       "      <td>Kevin Killian</td>\n",
       "      <td>10/10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1095724800</td>\n",
       "      <td>Really Enjoyed It</td>\n",
       "      <td>I don't care much for Dr. Seuss but after read...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A3UH4UZ4RSVO82</td>\n",
       "      <td>John Granger</td>\n",
       "      <td>10/11</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1078790400</td>\n",
       "      <td>Essential for every personal and Public Library</td>\n",
       "      <td>If people become the books they read and if \"t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A2MVUWT453QH61</td>\n",
       "      <td>Roy E. Perry \"amateur philosopher\"</td>\n",
       "      <td>7/7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1090713600</td>\n",
       "      <td>Phlip Nel gives silly Seuss a serious treatment</td>\n",
       "      <td>Theodore Seuss Geisel (1904-1991), aka &amp;quot;D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A22X4XUPKF66MR</td>\n",
       "      <td>D. H. Richards \"ninthwavestore\"</td>\n",
       "      <td>3/3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1107993600</td>\n",
       "      <td>Good academic overview</td>\n",
       "      <td>Philip Nel - Dr. Seuss: American IconThis is b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id                           Title  Price         User_id  \\\n",
       "0  1882931173  Its Only Art If Its Well Hung!    NaN   AVCGYZL8FQQTD   \n",
       "1  0826414346        Dr. Seuss: American Icon    NaN  A30TK6U7DNS82R   \n",
       "2  0826414346        Dr. Seuss: American Icon    NaN  A3UH4UZ4RSVO82   \n",
       "3  0826414346        Dr. Seuss: American Icon    NaN  A2MVUWT453QH61   \n",
       "4  0826414346        Dr. Seuss: American Icon    NaN  A22X4XUPKF66MR   \n",
       "\n",
       "                          profileName review/helpfulness  review/score  \\\n",
       "0               Jim of Oz \"jim-of-oz\"                7/7           4.0   \n",
       "1                       Kevin Killian              10/10           5.0   \n",
       "2                        John Granger              10/11           5.0   \n",
       "3  Roy E. Perry \"amateur philosopher\"                7/7           4.0   \n",
       "4     D. H. Richards \"ninthwavestore\"                3/3           4.0   \n",
       "\n",
       "   review/time                                   review/summary  \\\n",
       "0    940636800           Nice collection of Julie Strain images   \n",
       "1   1095724800                                Really Enjoyed It   \n",
       "2   1078790400  Essential for every personal and Public Library   \n",
       "3   1090713600  Phlip Nel gives silly Seuss a serious treatment   \n",
       "4   1107993600                           Good academic overview   \n",
       "\n",
       "                                         review/text  \n",
       "0  This is only for Julie Strain fans. It's a col...  \n",
       "1  I don't care much for Dr. Seuss but after read...  \n",
       "2  If people become the books they read and if \"t...  \n",
       "3  Theodore Seuss Geisel (1904-1991), aka &quot;D...  \n",
       "4  Philip Nel - Dr. Seuss: American IconThis is b...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>User_id</th>\n",
       "      <th>profileName</th>\n",
       "      <th>review/helpfulness</th>\n",
       "      <th>review/score</th>\n",
       "      <th>review/time</th>\n",
       "      <th>review/summary</th>\n",
       "      <th>review/text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1882931173</td>\n",
       "      <td>Its Only Art If Its Well Hung!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AVCGYZL8FQQTD</td>\n",
       "      <td>Jim of Oz \"jim-of-oz\"</td>\n",
       "      <td>7/7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>940636800</td>\n",
       "      <td>Nice collection of Julie Strain images</td>\n",
       "      <td>This is only for Julie Strain fans. It's a col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A30TK6U7DNS82R</td>\n",
       "      <td>Kevin Killian</td>\n",
       "      <td>10/10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1095724800</td>\n",
       "      <td>Really Enjoyed It</td>\n",
       "      <td>I don't care much for Dr. Seuss but after read...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A3UH4UZ4RSVO82</td>\n",
       "      <td>John Granger</td>\n",
       "      <td>10/11</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1078790400</td>\n",
       "      <td>Essential for every personal and Public Library</td>\n",
       "      <td>If people become the books they read and if \"t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A2MVUWT453QH61</td>\n",
       "      <td>Roy E. Perry \"amateur philosopher\"</td>\n",
       "      <td>7/7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1090713600</td>\n",
       "      <td>Phlip Nel gives silly Seuss a serious treatment</td>\n",
       "      <td>Theodore Seuss Geisel (1904-1991), aka &amp;quot;D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A22X4XUPKF66MR</td>\n",
       "      <td>D. H. Richards \"ninthwavestore\"</td>\n",
       "      <td>3/3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1107993600</td>\n",
       "      <td>Good academic overview</td>\n",
       "      <td>Philip Nel - Dr. Seuss: American IconThis is b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id                           Title  Price         User_id  \\\n",
       "0  1882931173  Its Only Art If Its Well Hung!    NaN   AVCGYZL8FQQTD   \n",
       "1  0826414346        Dr. Seuss: American Icon    NaN  A30TK6U7DNS82R   \n",
       "2  0826414346        Dr. Seuss: American Icon    NaN  A3UH4UZ4RSVO82   \n",
       "3  0826414346        Dr. Seuss: American Icon    NaN  A2MVUWT453QH61   \n",
       "4  0826414346        Dr. Seuss: American Icon    NaN  A22X4XUPKF66MR   \n",
       "\n",
       "                          profileName review/helpfulness  review/score  \\\n",
       "0               Jim of Oz \"jim-of-oz\"                7/7           4.0   \n",
       "1                       Kevin Killian              10/10           5.0   \n",
       "2                        John Granger              10/11           5.0   \n",
       "3  Roy E. Perry \"amateur philosopher\"                7/7           4.0   \n",
       "4     D. H. Richards \"ninthwavestore\"                3/3           4.0   \n",
       "\n",
       "   review/time                                   review/summary  \\\n",
       "0    940636800           Nice collection of Julie Strain images   \n",
       "1   1095724800                                Really Enjoyed It   \n",
       "2   1078790400  Essential for every personal and Public Library   \n",
       "3   1090713600  Phlip Nel gives silly Seuss a serious treatment   \n",
       "4   1107993600                           Good academic overview   \n",
       "\n",
       "                                         review/text  \n",
       "0  This is only for Julie Strain fans. It's a col...  \n",
       "1  I don't care much for Dr. Seuss but after read...  \n",
       "2  If people become the books they read and if \"t...  \n",
       "3  Theodore Seuss Geisel (1904-1991), aka &quot;D...  \n",
       "4  Philip Nel - Dr. Seuss: American IconThis is b...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "import time\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('E:/Master_thesis_REV/Datasets/Dataset_amazon_book_reviews/archive/Books_rating.csv', encoding='utf-8')\n",
    "\n",
    "# Display the first few rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the LOKY_MAX_CPU_COUNT environment variable\n",
    "os.environ[\"LOKY_MAX_CPU_COUNT\"] = \"12\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns in the DataFrame: Index(['Id', 'Title', 'Price', 'User_id', 'profileName', 'review/helpfulness',\n",
      "       'review/score', 'review/time', 'review/summary', 'review/text'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# columns available in the DataFrame\n",
    "print(\"Available columns in the DataFrame:\", df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column before dropna:\n",
      "review/score               0\n",
      "Price                2518829\n",
      "helpfulness_ratio     885732\n",
      "review/text                8\n",
      "dtype: int64\n",
      "Missing values in each column after dropna:\n",
      "review/score         0\n",
      "Price                0\n",
      "helpfulness_ratio    0\n",
      "review/text          0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>User_id</th>\n",
       "      <th>profileName</th>\n",
       "      <th>review/helpfulness</th>\n",
       "      <th>review/score</th>\n",
       "      <th>review/time</th>\n",
       "      <th>review/summary</th>\n",
       "      <th>review/text</th>\n",
       "      <th>helpfulness_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0829814000</td>\n",
       "      <td>Wonderful Worship in Smaller Churches</td>\n",
       "      <td>19.40</td>\n",
       "      <td>AZ0IOBU20TBOP</td>\n",
       "      <td>Rev. Pamela Tinnin</td>\n",
       "      <td>8/10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>991440000</td>\n",
       "      <td>Outstanding Resource for Small Church Pastors</td>\n",
       "      <td>I just finished the book, &amp;quot;Wonderful Wors...</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0829814000</td>\n",
       "      <td>Wonderful Worship in Smaller Churches</td>\n",
       "      <td>19.40</td>\n",
       "      <td>A373VVEU6Z9M0N</td>\n",
       "      <td>Dr. Terry W. Dorsett</td>\n",
       "      <td>1/1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1291766400</td>\n",
       "      <td>Small Churches CAN Have Wonderful Worship</td>\n",
       "      <td>Many small churches feel like they can not hav...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0829814000</td>\n",
       "      <td>Wonderful Worship in Smaller Churches</td>\n",
       "      <td>19.40</td>\n",
       "      <td>AGKGOH65VTRR4</td>\n",
       "      <td>Cynthia L. Lajoy \"Cindy La Joy\"</td>\n",
       "      <td>1/1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1248307200</td>\n",
       "      <td>Not Just for Pastors!</td>\n",
       "      <td>I just finished reading this amazing book and ...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0829814000</td>\n",
       "      <td>Wonderful Worship in Smaller Churches</td>\n",
       "      <td>19.40</td>\n",
       "      <td>A3OQWLU31BU1Y</td>\n",
       "      <td>Maxwell Grant</td>\n",
       "      <td>1/1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1222560000</td>\n",
       "      <td>Small church pastor? This is the book on worship</td>\n",
       "      <td>I hadn't been a small church pastor very long ...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0595344550</td>\n",
       "      <td>Whispers of the Wicked Saints</td>\n",
       "      <td>10.95</td>\n",
       "      <td>A3Q12RK71N74LB</td>\n",
       "      <td>Book Reader</td>\n",
       "      <td>7/11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1117065600</td>\n",
       "      <td>not good</td>\n",
       "      <td>I bought this book because I read some glowing...</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id                                  Title  Price         User_id  \\\n",
       "10  0829814000  Wonderful Worship in Smaller Churches  19.40   AZ0IOBU20TBOP   \n",
       "11  0829814000  Wonderful Worship in Smaller Churches  19.40  A373VVEU6Z9M0N   \n",
       "12  0829814000  Wonderful Worship in Smaller Churches  19.40   AGKGOH65VTRR4   \n",
       "13  0829814000  Wonderful Worship in Smaller Churches  19.40   A3OQWLU31BU1Y   \n",
       "14  0595344550          Whispers of the Wicked Saints  10.95  A3Q12RK71N74LB   \n",
       "\n",
       "                        profileName review/helpfulness  review/score  \\\n",
       "10               Rev. Pamela Tinnin               8/10           5.0   \n",
       "11             Dr. Terry W. Dorsett                1/1           5.0   \n",
       "12  Cynthia L. Lajoy \"Cindy La Joy\"                1/1           5.0   \n",
       "13                    Maxwell Grant                1/1           5.0   \n",
       "14                      Book Reader               7/11           1.0   \n",
       "\n",
       "    review/time                                    review/summary  \\\n",
       "10    991440000     Outstanding Resource for Small Church Pastors   \n",
       "11   1291766400         Small Churches CAN Have Wonderful Worship   \n",
       "12   1248307200                             Not Just for Pastors!   \n",
       "13   1222560000  Small church pastor? This is the book on worship   \n",
       "14   1117065600                                          not good   \n",
       "\n",
       "                                          review/text  helpfulness_ratio  \n",
       "10  I just finished the book, &quot;Wonderful Wors...           0.800000  \n",
       "11  Many small churches feel like they can not hav...           1.000000  \n",
       "12  I just finished reading this amazing book and ...           1.000000  \n",
       "13  I hadn't been a small church pastor very long ...           1.000000  \n",
       "14  I bought this book because I read some glowing...           0.636364  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to safely parse the helpfulness ratio\n",
    "def parse_helpfulness_ratio(helpfulness):\n",
    "    try:\n",
    "        votes = list(map(int, helpfulness.split('/')))\n",
    "        if len(votes) == 2 and votes[1] != 0:\n",
    "            return votes[0] / votes[1]\n",
    "    except:\n",
    "        return np.nan\n",
    "    return np.nan\n",
    "\n",
    "# Calculate helpfulness ratio using the safe function\n",
    "df['helpfulness_ratio'] = df['review/helpfulness'].apply(parse_helpfulness_ratio)\n",
    "\n",
    "# Ensure all required columns are available before dropping NaNs\n",
    "required_columns = ['review/score', 'Price', 'helpfulness_ratio', 'review/text']\n",
    "\n",
    "# Check for missing values specifically in these columns\n",
    "missing_data = df[required_columns].isnull().sum()\n",
    "print(\"Missing values in each column before dropna:\")\n",
    "print(missing_data)\n",
    "\n",
    "# Drop rows with missing values in these columns\n",
    "df.dropna(subset=required_columns, inplace=True)\n",
    "\n",
    "# Verify that the required columns have no missing values after cleaning\n",
    "missing_data_after = df[required_columns].isnull().sum()\n",
    "print(\"Missing values in each column after dropna:\")\n",
    "print(missing_data_after)\n",
    "\n",
    "# Display the first few rows after cleaning\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356273, 11)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed DataFrame shape: (356273, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>helpfulness_ratio</th>\n",
       "      <th>review_text_encoded</th>\n",
       "      <th>review_summary_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19.40</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>19.40</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>19.40</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>19.40</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10.95</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Price  helpfulness_ratio  review_text_encoded  review_summary_encoded\n",
       "10  19.40           0.800000             0.000003                0.000003\n",
       "11  19.40           1.000000             0.000003                0.000003\n",
       "12  19.40           1.000000             0.000003                0.000003\n",
       "13  19.40           1.000000             0.000003                0.000003\n",
       "14  10.95           0.636364             0.000003                0.000031"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill NaN values in text columns with empty strings\n",
    "df['review/text'].fillna('', inplace=True)\n",
    "df['review/summary'].fillna('', inplace=True)\n",
    "\n",
    "# Function for frequency encoding\n",
    "def frequency_encoding(column):\n",
    "    freq = column.value_counts() / len(column)\n",
    "    return column.map(freq)\n",
    "\n",
    "# Apply frequency encoding to the text columns\n",
    "df['review_text_encoded'] = frequency_encoding(df['review/text'])\n",
    "df['review_summary_encoded'] = frequency_encoding(df['review/summary'])\n",
    "\n",
    "# Combine the encoded features with other numeric features\n",
    "processed_df = pd.concat([df[['Price', 'helpfulness_ratio', 'review_text_encoded', 'review_summary_encoded']]], axis=1)\n",
    "\n",
    "# Verify the shape of the processed DataFrame\n",
    "print(\"Processed DataFrame shape:\", processed_df.shape)\n",
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (356273, 4), y shape: (356273,)\n"
     ]
    }
   ],
   "source": [
    "# Define features (X) and target (y)\n",
    "X = processed_df\n",
    "y = df['review/score']\n",
    "\n",
    "# Display the shapes of X and y\n",
    "print(f'X shape: {X.shape}, y shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to sample data (updated to handle full dataset properly)\n",
    "def sample_data(X, y, sample_size):\n",
    "    if isinstance(sample_size, float):\n",
    "        if 0 < sample_size < 1.0:\n",
    "            return train_test_split(X, y, test_size=0.1, train_size=sample_size, random_state=42)\n",
    "        elif sample_size == 1.0:\n",
    "            # Use the entire dataset for training, leave a small portion for testing\n",
    "            return train_test_split(X, y, test_size=0.001, random_state=42)\n",
    "        else:\n",
    "            raise ValueError(\"sample_size as float must be in the range (0.0, 1.0) or equal to 1.0.\")\n",
    "    elif isinstance(sample_size, int):\n",
    "        if sample_size > len(X):\n",
    "            raise ValueError(f\"sample_size {sample_size} exceeds the number of available samples {len(X)}.\")\n",
    "        sampled_X = X.sample(n=sample_size, random_state=42)\n",
    "        sampled_y = y.loc[sampled_X.index]\n",
    "        return train_test_split(sampled_X, sampled_y, test_size=0.1, random_state=42)\n",
    "    else:\n",
    "        raise ValueError(\"sample_size must be a float or an integer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# Function to calculate and return metrics\n",
    "def calculate_metrics(X_train, X_test, y_train, y_test):\n",
    "    lgb_model = lgb.LGBMRegressor()\n",
    "\n",
    "    # # Define hyperparameters for RandomizedSearchCV\n",
    "    # param_distributions = {\n",
    "    #     'num_leaves': [31, 50, 100],\n",
    "    #     'learning_rate': [0.01, 0.05, 0.1],\n",
    "    #     'n_estimators': [100, 200, 500],\n",
    "    #     'max_depth': [5, 10, 20],\n",
    "    # }\n",
    "\n",
    "    param_distributions = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'num_leaves': [31, 50],\n",
    "    'min_child_weight': [0.001, 0.01, 0.1,1.0],\n",
    "    'subsample': [0.6, 0.8],\n",
    "    'colsample_bytree': [0.6, 0.8],\n",
    "    'force_row_wise': [True]   \n",
    "}\n",
    "\n",
    "    random_search = RandomizedSearchCV(lgb_model, param_distributions, n_iter=30, cv=5, scoring='neg_mean_squared_error', random_state=42, n_jobs=-1, verbose=2)\n",
    "\n",
    "    start_time = time.time()\n",
    "    start_cpu = psutil.cpu_percent(interval=None)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    end_cpu = psutil.cpu_percent(interval=None)\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calculate time and CPU usage\n",
    "    execution_time = end_time - start_time\n",
    "    avg_cpu_usage = (start_cpu + end_cpu) / 2\n",
    "\n",
    "    y_pred = random_search.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    # Calculate the range of the target variable\n",
    "    target_range = y_train.max() - y_train.min()\n",
    "\n",
    "    # Calculate normalized RMSE (nRMSE)\n",
    "    nrmse = rmse / target_range\n",
    "    \n",
    "    memory_usage_MB = X_train.memory_usage(deep=True).sum() / (1024 ** 2)\n",
    "    normalized_time = execution_time / memory_usage_MB\n",
    "    \n",
    "    return {\n",
    "        'RMSE': rmse,\n",
    "        'MAPE': mape,\n",
    "        'R2': r2,\n",
    "        'MSE': mse,\n",
    "        'nRMSE': nrmse,  # Normalized RMSE\n",
    "        'Execution Time (Raw)': execution_time,  # Raw execution time\n",
    "        'Normalized Time (s/MB)': normalized_time,  # Normalized execution time\n",
    "        'Average CPU Usage': avg_cpu_usage\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[LightGBM] [Info] Total Bins 654\n",
      "[LightGBM] [Info] Number of data points in the train set: 355916, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.133849\n",
      "Metrics for sample size 1.0:\n",
      "RMSE: 1.1086637519374247\n",
      "MAPE: 0.3519675986470316\n",
      "R2: 0.2087640074774325\n",
      "MSE: 1.2291353148599675\n",
      "nRMSE: 0.2771659379843562\n",
      "Execution Time (Raw): 186.25634598731995\n",
      "Normalized Time (s/MB): 13.71840084809337\n",
      "Average CPU Usage: 96.30000000000001\n",
      "Sample Size: 1.0\n",
      "--------------------------------------------------\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[LightGBM] [Info] Total Bins 654\n",
      "[LightGBM] [Info] Number of data points in the train set: 178136, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.133656\n",
      "Metrics for sample size 0.5:\n",
      "RMSE: 1.1582061623414353\n",
      "MAPE: 0.3965429484078218\n",
      "R2: 0.20737124138145402\n",
      "MSE: 1.3414415144856748\n",
      "nRMSE: 0.2895515405853588\n",
      "Execution Time (Raw): 118.62215161323547\n",
      "Normalized Time (s/MB): 17.456373395888534\n",
      "Average CPU Usage: 99.9\n",
      "Sample Size: 0.5\n",
      "--------------------------------------------------\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[LightGBM] [Info] Total Bins 653\n",
      "[LightGBM] [Info] Number of data points in the train set: 89068, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.134279\n",
      "Metrics for sample size 0.25:\n",
      "RMSE: 1.163154545058644\n",
      "MAPE: 0.400154734999769\n",
      "R2: 0.2005838327956907\n",
      "MSE: 1.3529284956905812\n",
      "nRMSE: 0.290788636264661\n",
      "Execution Time (Raw): 86.12360215187073\n",
      "Normalized Time (s/MB): 25.347807924843938\n",
      "Average CPU Usage: 97.1\n",
      "Sample Size: 0.25\n",
      "--------------------------------------------------\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[LightGBM] [Info] Total Bins 651\n",
      "[LightGBM] [Info] Number of data points in the train set: 44534, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.137333\n",
      "Metrics for sample size 0.125:\n",
      "RMSE: 1.1681517573334488\n",
      "MAPE: 0.40264951540756844\n",
      "R2: 0.19370008074585754\n",
      "MSE: 1.3645785281612248\n",
      "nRMSE: 0.2920379393333622\n",
      "Execution Time (Raw): 70.11408543586731\n",
      "Normalized Time (s/MB): 41.27180763573899\n",
      "Average CPU Usage: 98.4\n",
      "Sample Size: 0.125\n",
      "--------------------------------------------------\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[LightGBM] [Info] Total Bins 51\n",
      "[LightGBM] [Info] Number of data points in the train set: 90, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.188889\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Metrics for sample size 100:\n",
      "RMSE: 1.0464300993953712\n",
      "MAPE: 0.2994558604260656\n",
      "R2: 0.2650899644828142\n",
      "MSE: 1.0950159529206067\n",
      "nRMSE: 0.2616075248488428\n",
      "Execution Time (Raw): 4.428908824920654\n",
      "Normalized Time (s/MB): 1290.0131944444445\n",
      "Average CPU Usage: 94.65\n",
      "Sample Size: 100\n",
      "--------------------------------------------------\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[LightGBM] [Info] Total Bins 364\n",
      "[LightGBM] [Info] Number of data points in the train set: 900, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.173333\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Metrics for sample size 1000:\n",
      "RMSE: 1.3189870757552424\n",
      "MAPE: 0.49979530768897673\n",
      "R2: 0.03749548768499811\n",
      "MSE: 1.7397269060093656\n",
      "nRMSE: 0.3297467689388106\n",
      "Execution Time (Raw): 29.82383918762207\n",
      "Normalized Time (s/MB): 868.6822777777778\n",
      "Average CPU Usage: 96.6\n",
      "Sample Size: 1000\n",
      "--------------------------------------------------\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[LightGBM] [Info] Total Bins 604\n",
      "[LightGBM] [Info] Number of data points in the train set: 9000, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.130222\n",
      "Metrics for sample size 10000:\n",
      "RMSE: 1.2832882742812082\n",
      "MAPE: 0.49354240026092283\n",
      "R2: 0.15975379047701488\n",
      "MSE: 1.6468287949076412\n",
      "nRMSE: 0.32082206857030204\n",
      "Execution Time (Raw): 56.93623661994934\n",
      "Normalized Time (s/MB): 165.83880902777778\n",
      "Average CPU Usage: 92.80000000000001\n",
      "Sample Size: 10000\n",
      "--------------------------------------------------\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[LightGBM] [Info] Total Bins 653\n",
      "[LightGBM] [Info] Number of data points in the train set: 90000, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.131567\n",
      "Metrics for sample size 100000:\n",
      "RMSE: 1.1544870991752576\n",
      "MAPE: 0.3928599272783105\n",
      "R2: 0.19492294112075326\n",
      "MSE: 1.3328404621621013\n",
      "nRMSE: 0.2886217747938144\n",
      "Execution Time (Raw): 83.2411413192749\n",
      "Normalized Time (s/MB): 24.245739722222222\n",
      "Average CPU Usage: 97.25\n",
      "Sample Size: 100000\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Define sample sizes\n",
    "sample_sizes = [1.0, 0.5, 0.25, 0.125, 100, 1000, 10000, 100000]\n",
    "\n",
    "# Initialize metrics storage\n",
    "metrics_list = []\n",
    "total_execution_time = 0\n",
    "total_cpu_usage = 0\n",
    "total_memory_usage_MB = 0\n",
    "\n",
    "# Loop through each sample size\n",
    "for size in sample_sizes:\n",
    "    try:\n",
    "        X_train_sample, X_test_sample, y_train_sample, y_test_sample = sample_data(X, y, size)\n",
    "        metrics = calculate_metrics(X_train_sample, X_test_sample, y_train_sample, y_test_sample)\n",
    "        metrics['Sample Size'] = size\n",
    "        metrics_list.append(metrics)\n",
    "\n",
    "        # Accumulate total metrics\n",
    "        total_execution_time += metrics['Execution Time (Raw)']\n",
    "        total_cpu_usage += metrics['Average CPU Usage']\n",
    "        total_memory_usage_MB += X_train_sample.memory_usage(deep=True).sum() / (1024 ** 2)\n",
    "\n",
    "        print(f\"Metrics for sample size {size}:\")\n",
    "        for key, value in metrics.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for sample size {size}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Execution Time for Entire Process (Raw): 10 minutes and 35.55 seconds\n",
      "Total Normalized Execution Time for Entire Process: 21.70337451 seconds per MB\n",
      "Total Average CPU Usage for Entire Process: 96.62%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE</th>\n",
       "      <th>nRMSE</th>\n",
       "      <th>Execution Time (Raw)</th>\n",
       "      <th>Normalized Time (s/MB)</th>\n",
       "      <th>Average CPU Usage</th>\n",
       "      <th>Sample Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.108664</td>\n",
       "      <td>0.351968</td>\n",
       "      <td>0.208764</td>\n",
       "      <td>1.229135</td>\n",
       "      <td>0.277166</td>\n",
       "      <td>186.256346</td>\n",
       "      <td>13.718401</td>\n",
       "      <td>96.30</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.158206</td>\n",
       "      <td>0.396543</td>\n",
       "      <td>0.207371</td>\n",
       "      <td>1.341442</td>\n",
       "      <td>0.289552</td>\n",
       "      <td>118.622152</td>\n",
       "      <td>17.456373</td>\n",
       "      <td>99.90</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.163155</td>\n",
       "      <td>0.400155</td>\n",
       "      <td>0.200584</td>\n",
       "      <td>1.352928</td>\n",
       "      <td>0.290789</td>\n",
       "      <td>86.123602</td>\n",
       "      <td>25.347808</td>\n",
       "      <td>97.10</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.168152</td>\n",
       "      <td>0.402650</td>\n",
       "      <td>0.193700</td>\n",
       "      <td>1.364579</td>\n",
       "      <td>0.292038</td>\n",
       "      <td>70.114085</td>\n",
       "      <td>41.271808</td>\n",
       "      <td>98.40</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.046430</td>\n",
       "      <td>0.299456</td>\n",
       "      <td>0.265090</td>\n",
       "      <td>1.095016</td>\n",
       "      <td>0.261608</td>\n",
       "      <td>4.428909</td>\n",
       "      <td>1290.013194</td>\n",
       "      <td>94.65</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.318987</td>\n",
       "      <td>0.499795</td>\n",
       "      <td>0.037495</td>\n",
       "      <td>1.739727</td>\n",
       "      <td>0.329747</td>\n",
       "      <td>29.823839</td>\n",
       "      <td>868.682278</td>\n",
       "      <td>96.60</td>\n",
       "      <td>1000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.283288</td>\n",
       "      <td>0.493542</td>\n",
       "      <td>0.159754</td>\n",
       "      <td>1.646829</td>\n",
       "      <td>0.320822</td>\n",
       "      <td>56.936237</td>\n",
       "      <td>165.838809</td>\n",
       "      <td>92.80</td>\n",
       "      <td>10000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.154487</td>\n",
       "      <td>0.392860</td>\n",
       "      <td>0.194923</td>\n",
       "      <td>1.332840</td>\n",
       "      <td>0.288622</td>\n",
       "      <td>83.241141</td>\n",
       "      <td>24.245740</td>\n",
       "      <td>97.25</td>\n",
       "      <td>100000.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       RMSE      MAPE        R2       MSE     nRMSE  Execution Time (Raw)  \\\n",
       "0  1.108664  0.351968  0.208764  1.229135  0.277166            186.256346   \n",
       "1  1.158206  0.396543  0.207371  1.341442  0.289552            118.622152   \n",
       "2  1.163155  0.400155  0.200584  1.352928  0.290789             86.123602   \n",
       "3  1.168152  0.402650  0.193700  1.364579  0.292038             70.114085   \n",
       "4  1.046430  0.299456  0.265090  1.095016  0.261608              4.428909   \n",
       "5  1.318987  0.499795  0.037495  1.739727  0.329747             29.823839   \n",
       "6  1.283288  0.493542  0.159754  1.646829  0.320822             56.936237   \n",
       "7  1.154487  0.392860  0.194923  1.332840  0.288622             83.241141   \n",
       "\n",
       "   Normalized Time (s/MB)  Average CPU Usage  Sample Size  \n",
       "0               13.718401              96.30        1.000  \n",
       "1               17.456373              99.90        0.500  \n",
       "2               25.347808              97.10        0.250  \n",
       "3               41.271808              98.40        0.125  \n",
       "4             1290.013194              94.65      100.000  \n",
       "5              868.682278              96.60     1000.000  \n",
       "6              165.838809              92.80    10000.000  \n",
       "7               24.245740              97.25   100000.000  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert metrics to DataFrame\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "\n",
    "# Calculate total metrics\n",
    "total_avg_cpu_usage = total_cpu_usage / len(sample_sizes)\n",
    "normalized_total_time = total_execution_time / total_memory_usage_MB\n",
    "\n",
    "# Convert total execution time to minutes and seconds\n",
    "total_minutes = int(total_execution_time // 60)\n",
    "total_seconds = total_execution_time % 60\n",
    "\n",
    "# Display total metrics\n",
    "print(f\"Total Execution Time for Entire Process (Raw): {total_minutes} minutes and {total_seconds:.2f} seconds\")\n",
    "print(f\"Total Normalized Execution Time for Entire Process: {normalized_total_time:.8f} seconds per MB\")\n",
    "print(f\"Total Average CPU Usage for Entire Process: {total_avg_cpu_usage:.2f}%\")\n",
    "\n",
    "# Display the metrics DataFrame\n",
    "metrics_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
